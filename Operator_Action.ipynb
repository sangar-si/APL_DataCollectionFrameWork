{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "a5b463336524058ca0702ac80079a58bbd6cd5e21c156138aaf1d4d7b679b52f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import walk\n",
    "import re\n",
    "import sys\n",
    "import getpass\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading settings...\n",
      "\n",
      "            _____ _____          _   _ _____        _____ _   _ _______ _____ \n",
      "     /\\    / ____|_   _|   /\\   | \\ | |  __ \\ /\\   |_   _| \\ | |__   __/ ____|\n",
      "    /  \\  | (___   | |    /  \\  |  \\| | |__) /  \\    | | |  \\| |  | | | (___  \n",
      "   / /\\ \\  \\___ \\  | |   / /\\ \\ | . ` |  ___/ /\\ \\   | | | . ` |  | |  \\___ \\ \n",
      "  / ____ \\ ____) |_| |_ / ____ \\| |\\  | |  / ____ \\ _| |_| |\\  |  | |  ____) |\n",
      " /_/    \\_\\_____/|_____/_/    \\_\\_| \\_|_| /_/    \\_\\_____|_| \\_|  |_| |_____/ \n",
      "                                                                             \n",
      "Welcome to MI Analysis tool\n",
      "Choose your mode of operation\n",
      "1. Configuration mode...press 1\n",
      "2. User mode...press 2\n",
      "_________________________________________________\n",
      "User mode selected...Choose execution mode,\n",
      "1. Start new analysis\n",
      "2. Resume from old analysis\n",
      "Vocab File Checked...Found OK!\n",
      "Loading files...\n",
      "Detected  10  files in the directory\n",
      "10 / 10  files read successfully\n",
      "\n",
      "All files loaded\n",
      "Concatinating files...\n",
      "File concatination sucessful.\n",
      "Building temp file checkpoint...\n",
      "Checkpoint created... If unsuccessful, resume from here.\n",
      "Loading Temp file...\n",
      "Data loaded successfully.\n",
      "Vocab Building started...Reading file...\n",
      "Refresing vocab file...\n",
      "Vocab file is up to date...\n",
      "Extracting data from path...\n",
      "Data Extraction successful\n",
      "Adding to Data Frame\n",
      "Successful\n",
      "Normalizing User Data\n",
      "Add user details for  800xaappeng  in the /Utility_Files/Employee_details.xlsx file\n",
      "Add user details for  p00115543  in the /Utility_Files/Employee_details.xlsx file\n",
      "Add user details for  P00112581  in the /Utility_Files/Employee_details.xlsx file\n",
      "Successful\n",
      "Extracting Message Action\n",
      "Successful\n",
      "Vocab File Checked...Found OK!\n",
      "Building temp file checkpoint...\n",
      "Checkpoint created... If unsuccessful, resume from here.\n",
      "Deleting old temp file...\n",
      "Delete successful\n",
      "Building final report...\n",
      "Consolidated report built successfully. Thanks!\n",
      "Press any key to exit\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import walk\n",
    "import re\n",
    "import sys\n",
    "import getpass\n",
    "import time\n",
    "\n",
    "\n",
    "''' Update notes --- Beta V.1.1\n",
    "Added user more and configuration mode. Configuration mode allows us to reset the dictionary files\n",
    "Added config file to be able to work with\n",
    "Pending work:\n",
    "Change the code for resume logic to be able to handle resume from the start. \n",
    "'''\n",
    "#Function that will import all excel files in a folder\n",
    "#It will take in the path as input and return a dataframe will contain a concatination of all entries of all three files\n",
    "def apply_filter(filter_list,df):\n",
    "    fltr_cnt = len(filter_list)\n",
    "    print(\"Applying \",fltr_cnt,\" filters...\")\n",
    "    try:\n",
    "        for filter in filter_list:\n",
    "            df_copy = df.copy()\n",
    "            filter_data(df_copy,filter)\n",
    "    except:\n",
    "        print(\"Error applying filter\")\n",
    "        sys.exit(\"Exiting...\")\n",
    "    print(\"Filters applied successfully\")\n",
    "    return 0\n",
    "\n",
    "def parse_filter():\n",
    "    path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"filters.txt\"\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            filt = f.read()\n",
    "    except:\n",
    "        print(\"Error: filters.txt file not found\")\n",
    "        return []\n",
    "    filter_list = []\n",
    "    filt=filt.replace('\\n',\"\").replace(\" \",\"\").replace(\"Filter{\",\"\").replace(\"}\",\"\").replace(\"%\",\" \")\n",
    "    filt=filt.split(\";\")\n",
    "    if len(filt[-1])==0:\n",
    "        filt.pop()\n",
    "    for f in filt:\n",
    "        f = f.split(',')\n",
    "        f[0] = f[0].replace('FileName=','')\n",
    "        f[1] = int(f[1].replace('Save=',''))\n",
    "        f[2] = f[2].replace(\"(\",\"\").replace(\")\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").split('&')\n",
    "        f_list = []\n",
    "        for item in f[2]:\n",
    "            tup = item.split(\"=\")\n",
    "            tup[1] = list(tup[1].split(\"+\"))\n",
    "            tup = tuple(tup)\n",
    "            f_list.append(tup)\n",
    "        f_construct = tuple([f[0],f[1],f_list])\n",
    "        filter_list.append(f_construct)\n",
    "    return filter_list\n",
    "\n",
    "\n",
    "def save_df(df,filename):\n",
    "    print(\"Attempting to save file...\")\n",
    "    if filename == 'None':\n",
    "        print('Error: Invalid filename: ',filename)\n",
    "        sys.exit(\"Exiting...\")\n",
    "    i=0\n",
    "    try:\n",
    "        df.to_csv(filename+\".csv\")\n",
    "    except:\n",
    "\n",
    "        while(i<20):\n",
    "            try:\n",
    "                df.to_csv(filename+str(i)+\".csv\")\n",
    "            except:\n",
    "                i=i+1\n",
    "                continue\n",
    "            break\n",
    "    if i<20:\n",
    "        print(\"Saved successfully\")\n",
    "    else:\n",
    "        print(\"Save Failed. Delete old files if any\")\n",
    "\n",
    "def filter_data(df, filters):\n",
    "    ''' Filter format is like = (FileName = filename.xlsx,Save = 1 or 0,[(Col,[Val1,Val2]),(Col2,[Val1,Val2])])'''\n",
    "    print(\"Applying Filter...\")\n",
    "    filename = filters[0]\n",
    "    save = filters[1]\n",
    "    for filter in filters[2]:\n",
    "        col_name = filter[0]\n",
    "        values_list = filter[1]\n",
    "        for i in range(len(list(df.loc[:,'ObjectName'].values))):\n",
    "            row_ = df.loc[i,col_name]\n",
    "            if row_ not in values_list:\n",
    "                df.loc[i,\"FilterValue\"] = 0\n",
    "    df = df[df[\"FilterValue\"] == 1]\n",
    "    if save==1:\n",
    "        save_df(df,filename)\n",
    "    return df\n",
    "\n",
    "def filter_data_v2(df,filters):\n",
    "    #Efficient but needs to be refined\n",
    "    print(\"Applying Filter...\")\n",
    "    filename = filters[0]\n",
    "    save = filters[1]\n",
    "    for filter in filters[2]:\n",
    "        col_name = filter[0]\n",
    "        val_name = filter[1]\n",
    "        df = df[df[col_name] == val_name]\n",
    "    if save==1:\n",
    "        save_df(df,filename)\n",
    "    return df\n",
    "\n",
    "def remove_nan(data_f):\n",
    "    #Finding the last row of a file. Extra rows with nan entry is removed here. It also combines all the individual data frames \n",
    "    #into a single data frame\n",
    "    #print('Checking for junk values...')\n",
    "    l = len(data_f)\n",
    "    junk_frames = []\n",
    "    for i in range(l):\n",
    "        if str(data_f.loc[i,'UserAccount']) == 'nan':\n",
    "            junk_frames.append(i)\n",
    "    if len(junk_frames)>0:\n",
    "        # print(len(junk_frames),\" junk values found\")\n",
    "        #print(\"Removing junk frames...\")\n",
    "        data_f.drop(junk_frames,inplace=True)\n",
    "        #print('Successful.')\n",
    "    else:\n",
    "       pass\n",
    "       # print(\"No junk frames found.\")\n",
    "       \n",
    "def parse_config():\n",
    "    path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"settings.txt\"\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            conf = f.read()\n",
    "    except:\n",
    "        print(\"Error: Settings file not found\")\n",
    "        sys.exit()\n",
    "\n",
    "    conf = conf.replace(\" \",\"\").replace(\"\\n\",\"\").replace(';',\" \").replace(\"-{\",\" \").replace(\"}\",\"\").split()\n",
    "    conf_dict = {}\n",
    "    i=0\n",
    "    while(i<(len(conf))):\n",
    "        conf_dict[conf[i]] = conf[i+1]\n",
    "        i=i+2\n",
    "    return conf_dict\n",
    "\n",
    "def open_files_of_date(path):\n",
    "    print(\"Loading files...\")\n",
    "    f = []\n",
    "    for(_,_, filenames) in walk(path):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    for i in range(6):\n",
    "        print(f[i])\n",
    "\n",
    "\n",
    "def update_vocab_file():\n",
    "    pass\n",
    "\n",
    "\n",
    "def open_files_in_folder(path):\n",
    "    #Loading a list of files from a directory\n",
    "    print(\"Loading files...\")\n",
    "    f = []\n",
    "    for (_,_, filenames) in walk(path):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    print('Detected ',len(f),' files in the directory')\n",
    "    dat_frame=[]\n",
    "    for i in range(len(f)):\n",
    "        full_path = path+'\\\\'+f[i]\n",
    "        #print('Reading File ',f[i])\n",
    "        dat_f = pd.read_excel(full_path, index_col = None, header = 2,sheet_name=0, skiprows=0)\n",
    "        remove_nan(dat_f)\n",
    "        dat_frame.append(dat_f)\n",
    "        print(str(i+1),'/',str(len(f)),' files read successfully', end='\\r')\n",
    "    print(\"\\n\")\n",
    "    print(\"All files loaded\")\n",
    "    print(\"Concatinating files...\")\n",
    "    df_concat = pd.concat(dat_frame, ignore_index = True, sort = False)\n",
    "    print(\"File concatination sucessful.\")  \n",
    "    return df_concat\n",
    "#This helps us to open all the excel files in a folder\n",
    "\n",
    "def sort_by_time(df):\n",
    "    time_list = []\n",
    "    shift_list = []\n",
    "    for i in list(df.loc[:,\"EventTime\"].values):\n",
    "        split_val = i.replace(\"-\",\" \").replace(\":\",\" \").split(\" \")\n",
    "        #t_tuple = ((split_val[2]),(split_val[1]),(split_val[0]),(split_val[3]),(split_val[4]),(split_val[5]),0,0,0)\n",
    "        #print(t_tuple)\n",
    "        t_tuple = (int(split_val[3]),int(split_val[2]),int(split_val[1]),int(split_val[4]),int(split_val[5]),int(split_val[6]),0,0,0)\n",
    "        t_ticks = time.mktime(t_tuple)\n",
    "        time_list.append(t_ticks)\n",
    "        if (int(split_val[4])>=7) and (int(split_val[4])<15):\n",
    "            shift_list.append(\"First Shift\")\n",
    "        elif(int(split_val[4])>=15) and (int(split_val[4])<23):\n",
    "            shift_list.append(\"Second Shift\")\n",
    "        else:\n",
    "            shift_list.append(\"Night Shift\")\n",
    "    df[\"Shift\"]=shift_list\n",
    "    df[\"TimeTicks\"]=time_list\n",
    "    df.sort_values(\"TimeTicks\",inplace=True,ascending=True)\n",
    "\n",
    "def remove_dupes(df,filter_time_frame):\n",
    "    pass\n",
    "    \n",
    "def path_extraction(df):\n",
    "    block_list = [] #Block name that comes after root\n",
    "    seq_list = [] #individual sequence\n",
    "    change_type = [] #graphics change or logic related\n",
    "    equip_group = [] #Equipment group\n",
    "    end_obj = [] #End object\n",
    "    print(\"Extracting data from path...\")\n",
    "    for i in list(df.loc[:,\"Path\"].values):\n",
    "        loc_split = i.replace(\"]\",\"/\").replace(\"[Location Structure\",\"Graphic Action\").replace(\"[Control Structure\",\"Control Action\").replace(\"SPB_Block\",\"SPB\").replace(\"WBP_Block\",\"WPB\").replace(\"EmulsionBlock\",\"EB\").replace(\"RB_Block\",\"RB\").split(\"/\")\n",
    "        if loc_split[0]==\"Control Action\":\n",
    "            try:\n",
    "                seq_list.append(loc_split[8])\n",
    "            except:\n",
    "                seq_list.append('nan')\n",
    "            \n",
    "            try:\n",
    "                block_list.append(loc_split[3])\n",
    "            except:\n",
    "                block_list.append('nan')\n",
    "                \n",
    "            try:\n",
    "                change_type.append(loc_split[0])\n",
    "            except:\n",
    "                change_type.append(loc_split[0])\n",
    "                \n",
    "            try:    \n",
    "                equip_group.append(loc_split[7])\n",
    "            except:\n",
    "                equip_group.append(loc_split[-2])\n",
    "                \n",
    "            try:   \n",
    "                end_obj.append(loc_split[-1])\n",
    "            except:\n",
    "                end_obj.append(loc_split[-1])\n",
    "        else:\n",
    "            try:\n",
    "                block_list.append(loc_split[2])\n",
    "            except:\n",
    "                block_list.append('nan')\n",
    "                \n",
    "            try:\n",
    "                change_type.append(loc_split[0])\n",
    "            except:\n",
    "                change_type.append('nan')\n",
    "               \n",
    "            try:\n",
    "                end_obj.append(loc_split[-1])\n",
    "            except:\n",
    "                end_obj.append('nan')\n",
    "                \n",
    "            try:\n",
    "                equip_group.append(loc_split[3])\n",
    "            except:\n",
    "                equip_group.append('nan')\n",
    "                \n",
    "            try:\n",
    "                seq_list.append(loc_split[-2])\n",
    "            except:\n",
    "                seq_list.append('nan')  \n",
    "                \n",
    "    print(\"Data Extraction successful\")\n",
    "    print(\"Adding to Data Frame\")\n",
    "    df[\"Block\"] = block_list\n",
    "    df[\"Change_Type\"] = change_type\n",
    "    df[\"Equipment_Group\"] = equip_group\n",
    "    df[\"Sequence\"] = seq_list\n",
    "    df[\"Object_Interacted_With\"] = end_obj\n",
    "    print(\"Successful\")\n",
    "    \n",
    "def normalize_user_data(df, file_name = 'Employee_details.xlsx'):\n",
    "    user_id = []\n",
    "    user_name = []\n",
    "    user_dept = []\n",
    "    user_subdept = []\n",
    "    user_designation = []\n",
    "    uknown_id = []\n",
    "    emp_file_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name\n",
    "    emp_details = pd.read_excel(emp_file_path, index_col = 0, header = 0).transpose()\n",
    "    emp_dict = emp_details.to_dict(orient = 'series')\n",
    "    print(\"Normalizing User Data\")\n",
    "    for i in list(df.loc[:,\"UserAccount\"].values):\n",
    "        id_val = i[11:]\n",
    "        try:\n",
    "            emp_details_list = list(emp_dict[id_val].values)\n",
    "        except:\n",
    "            if id_val not in uknown_id:\n",
    "                print(\"Add user details for \",id_val,\" in the /Utility_Files/Employee_details.xlsx file\")\n",
    "                uknown_id.append(id_val)\n",
    "            emp_details_list = ['na','na','na','na']\n",
    "            \n",
    "        user_id.append(id_val)\n",
    "        user_name.append(emp_details_list[0])\n",
    "        user_designation.append(emp_details_list[1])\n",
    "        user_dept.append(emp_details_list[2])\n",
    "        user_subdept.append(emp_details_list[3])\n",
    "        \n",
    "\n",
    "    df[\"UserID\"] = user_id  \n",
    "    df[\"UserName\"] = user_name\n",
    "    df[\"UserDesignation\"] = user_designation\n",
    "    df[\"UserDept\"] = user_dept\n",
    "    df[\"User_Sub_Dept\"] = user_subdept  \n",
    "    print(\"Successful\")\n",
    "    del uknown_id\n",
    "\n",
    "def extract_msg(df):\n",
    "    message = []\n",
    "    print(\"Extracting Message Action\")\n",
    "    for i in list(df.loc[:,\"Message\"].values):\n",
    "        msg = i.split()\n",
    "        message.append(msg[0])\n",
    "    df[\"Action_Variable\"] = message\n",
    "    print(\"Successful\")\n",
    "\n",
    "def normalize_object_name(obj_name):\n",
    "    import re\n",
    "    index = re.search(\"[_]|[-]\",obj_name)\n",
    "    if index is None:\n",
    "        index = re.search(\"[0-9]\",obj_name)\n",
    "          \n",
    "        if index is None:\n",
    "            split_index = len(obj_name)\n",
    "        else:\n",
    "            split_index = index.span(0)[0]\n",
    "    else:\n",
    "        split_index = index.span(0)[0]\n",
    "    \n",
    "    return obj_name[0:split_index].lower()\n",
    "\n",
    "def obj_vocab_reader(obj_names, file_name = 'Equip_Vocab.xlsx', refresh = True):\n",
    "    print(\"Vocab Building started...Reading file...\")\n",
    "    if (refresh==False):\n",
    "        obj_vocab_dict_temp={}\n",
    "        obj_equ_list = {\"ID\":[],\"Object\":[],\"Object Type\":[]}\n",
    "    else:\n",
    "        obj_vocab_dict_temp={}\n",
    "        tmp_df = pd.read_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name,header = 0, index_col = 0)\n",
    "        id_list = list(tmp_df[\"ID\"].values)\n",
    "        object_list = list(tmp_df[\"Object\"])\n",
    "        object_type_list = list(tmp_df[\"Object Type\"])\n",
    "        obj_equ_list = {\"ID\":id_list,\"Object\":object_list,\"Object Type\":object_type_list}\n",
    "        for id_val in id_list:\n",
    "            obj_vocab_dict_temp[id_val] = None\n",
    "        print(\"Refresing vocab file...\")\n",
    "    entry_req = False\n",
    "    for obj_name in obj_names:\n",
    "        #We try to split the string at _ first. If _ is not found, then we split at 0-9. If that is not found then we\n",
    "        #retain the entire string\n",
    "        index = re.search(\"[_]|[-]\",obj_name)\n",
    "        if index is None:\n",
    "            index = re.search(\"[0-9]\",obj_name)\n",
    "            \n",
    "            if index is None:\n",
    "                split_index = len(obj_name)\n",
    "            else:\n",
    "                split_index = index.span(0)[0]\n",
    "        else:\n",
    "            split_index = index.span(0)[0]\n",
    "            \n",
    "        if obj_name[0:split_index].lower() in obj_vocab_dict_temp:\n",
    "            pass\n",
    "        else:\n",
    "            obj_vocab_dict_temp[obj_name[0:split_index].lower()]=None\n",
    "            obj_equ_list[\"ID\"].append(obj_name[0:split_index].lower())\n",
    "            obj_equ_list[\"Object\"].append(obj_name)\n",
    "            obj_equ_list[\"Object Type\"].append(None)\n",
    "            entry_req = True\n",
    "            \n",
    "    if entry_req:\n",
    "        print(\"Vocab file needs to be updated...Please make changes in Equip_Vocab.xlsx\")\n",
    "        equip_vocab_df = pd.DataFrame(obj_equ_list)\n",
    "        equip_vocab_df.to_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name)\n",
    "        print(\"Vocab Building completed...File Saved\")\n",
    "    else:\n",
    "        print(\"Vocab file is up to date...\")\n",
    "\n",
    "def object_vocab_file_check(file_name = 'Equip_Vocab.xlsx'):\n",
    "    \n",
    "    vocab_df = pd.read_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name,header=0,index_col=1)\n",
    "    for i in list(vocab_df.loc[:,\"Object Type\"]):\n",
    "        if \"nan\" == str(i):\n",
    "            raise Exception(\"Vocab file has incomplete cells. Complete the vocab file before proceeding forward\")\n",
    "    print(\"Vocab File Checked...Found OK!\")\n",
    "    vocab_df = vocab_df.drop(columns=[\"Unnamed: 0\",\"Object\"]).to_dict()\n",
    "    return  vocab_df[\"Object Type\"]\n",
    "\n",
    "def object_type_builder(df, vocab_df, daily_mode = 0):\n",
    "    object_type = []\n",
    "    for object_name in list(df.loc[:,\"ObjectName\"].values):\n",
    "        norm_obj_name = normalize_object_name(object_name)\n",
    "        try:\n",
    "            object_type.append(vocab_df[norm_obj_name])\n",
    "        except:\n",
    "            if daily_mode == 1:\n",
    "                object_type.append('nan')\n",
    "            else:\n",
    "                print(\"Error: Key Error. Vocab file is not up to date.\")\n",
    "                sys.exit(\"Exiting...\")               \n",
    "    df[\"Object_Type\"] = object_type\n",
    "    \n",
    "def action_definition_dict_build_v2(df):\n",
    "    \"\"\"\n",
    "    #Accepts data frame as input\n",
    "    #Builds a dictionary of dictionaries. Outputs an excel file which allows us to define actions that are acceptable as MI\n",
    "    \"\"\"\n",
    "    action_var = []\n",
    "    for i in df.loc[:,\"Action_Variable\"]:\n",
    "        action_var.append(i)\n",
    "    \n",
    "    action_var_set = set(action_var)\n",
    "    action_var_set = list(action_var_set)\n",
    "    definition_set = [None for c in range(len(action_var_set))]\n",
    "    action_dict={\"Action_Value\":action_var_set,\"Def\":definition_set}    \n",
    "    action_df = pd.DataFrame(action_dict)\n",
    "    action_df.to_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"Action_definition_Final.xlsx\")\n",
    "    \n",
    "def action_definition(df, action_file_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"Action_definition_Final.xlsx\"):\n",
    "    \"\"\"\n",
    "    #This adds action definition to the data frame\n",
    "    \"\"\"\n",
    "    action_def = pd.read_excel(action_file_path, index_col = 1).drop(columns=[\"Unnamed: 0\"])\n",
    "    action_dict = action_def.to_dict()\n",
    "    action_class = []\n",
    "    for item in df.loc[:,\"Action_Variable\"]:\n",
    "        try:\n",
    "            class_type = str(action_dict[\"Def\"][item])\n",
    "        except KeyError:\n",
    "            class_type = \"NA\"\n",
    "        else:\n",
    "            if str(class_type)=='nan':\n",
    "                class_type = \"NA\"\n",
    "        \n",
    "        force_ret = re.findall(\"Force\",item)\n",
    "        if len(force_ret)>0:\n",
    "            class_type = \"MI\"\n",
    "        action_class.append(class_type)\n",
    "    return action_class\n",
    "\n",
    "def read_config():\n",
    "    logo_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"config.txt\"\n",
    "    with open(logo_path) as f:\n",
    "        print(f.read())\n",
    "\n",
    "def config_reset():\n",
    "    path = os.getcwd()     \n",
    "    path = path + \"\\\\\"+ \"Operator_Action_Files\"+\"\\\\\"\n",
    "    df = open_files_in_folder(path)\n",
    "    extract_msg(df)\n",
    "    #oper_data_collective.to_excel('All_oper_action_july.xlsx')\n",
    "\n",
    "    obj_vocab_reader(list(df.loc[:,\"ObjectName\"].values), refresh = False) #Reset the equip vocab file\n",
    "    action_definition_dict_build_v2(df) #Only run this if you want to update the action definition\n",
    "    print(\"Equipment Vocab file regenerated. Action Definition regenerated.\")\n",
    "    sys.exit(\"Exiting...\")\n",
    "\n",
    "def admin_mode_check():\n",
    "    u_name = getpass.getpass(prompt='Username:')\n",
    "    p_word = getpass.getpass(prompt='Password:')    \n",
    "    if u_name == \"admin\" and p_word ==\"admin\":\n",
    "        config_reset()\n",
    "    else:\n",
    "        print(\"Invalid Credentials...\")\n",
    "        sys.exit(\"Exiting...\")\n",
    "\n",
    "def resume_temp():\n",
    "    temp_path = os.getcwd()+\"\\\\\"+\"temp\"+\"\\\\\"+\"consolidated_dat.pkl\"\n",
    "    temp_path_1 = os.getcwd()+\"\\\\\"+\"temp\"+\"\\\\\"+\"combined_dat.pkl\"\n",
    "    print(\"Loading Temp file...\")\n",
    "    try:\n",
    "        df = pd.read_pickle(temp_path)        \n",
    "    except:\n",
    "        try:    \n",
    "            df = pd.read_pickle(temp_path_1)\n",
    "        except:\n",
    "            print(\"Temp file load error. Check if temp file is available. Else, start new analysis.\")\n",
    "            print(\"Press any key to exit...\")\n",
    "            _ = input(\"\")\n",
    "            sys.exit(\"Exiting...\")\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return [0,df]\n",
    "    print(\"Temp file loaded successfully.\")\n",
    "\n",
    "    try:\n",
    "        print(\"Attempting excel file build operation...\")\n",
    "        df.to_excel(\"Consolidated_Report.xlsx\")\n",
    "        print(\"Consolidated report built successfully. Thanks!\")\n",
    "\n",
    "    except:\n",
    "        print(\"Excel file build Failed... Attempting csv file build...\")\n",
    "        try:\n",
    "            df.to_csv(\"Consolidated_Report.csv\")\n",
    "            print(\"Consolidated report built successfully. Thanks!\")\n",
    "        except:\n",
    "            print(\"CSV Build also failed... Try running from script\")\n",
    "            sys.exit(\"Exiting...\")\n",
    "    os.remove(temp_path)\n",
    "    os.remove(temp_path_1)\n",
    "    print(\"Press any key to exit...\")\n",
    "    _ = input(\"\")\n",
    "\n",
    "def print_logo():\n",
    "    try:\n",
    "        logo_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"logo.txt\"\n",
    "        with open(logo_path) as f:\n",
    "            print(f.read())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def detailed_mode():\n",
    "    print_logo()\n",
    "    print(\"Welcome to MI Analysis tool\")\n",
    "    print(\"Choose your mode of operation\")\n",
    "    print(\"1. Configuration mode...press 1\")\n",
    "    print(\"2. User mode...press 2\")\n",
    "    mode = input(\"\")\n",
    "    if mode == '1':\n",
    "        admin_mode_check()\n",
    "    print(\"_________________________________________________\")\n",
    "    print(\"User mode selected...Choose execution mode,\")\n",
    "    print(\"1. Start new analysis\")\n",
    "    print(\"2. Resume from old analysis\")\n",
    "    ret = 1\n",
    "    mode = input(\"\")\n",
    "    if mode == '2':\n",
    "        r = resume_temp()\n",
    "        ret = r[0]\n",
    "        df = r[1]\n",
    "    if ret == 1:\n",
    "        vocab_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"Equip_Vocab.xlsx\"\n",
    "        vocab_df = pd.read_excel(vocab_path,header=0,index_col=1).drop(columns=[\"Unnamed: 0\",\"Object\"]).to_dict()\n",
    "        object_vocab_file_check()\n",
    "        path = os.getcwd()     \n",
    "        path = path + \"\\\\\"+ \"Operator_Action_Files\"+\"\\\\\"\n",
    "        df = open_files_in_folder(path)\n",
    "        #oper_data_collective.to_excel('All_oper_action_july.xlsx')\n",
    "        print(\"Building temp file checkpoint...\")\n",
    "        temp_path_1 =os.getcwd()+\"\\\\\"+\"temp\"+\"\\\\\"+\"combined_dat.pkl\" \n",
    "        df.to_pickle(temp_path_1)\n",
    "        print(\"Checkpoint created... If unsuccessful, resume from here.\")\n",
    "        r = resume_temp()\n",
    "        ret = r[0]\n",
    "        df = r[1]\n",
    "    if ret == 0:\n",
    "        obj_vocab_reader(list(df.loc[:,\"ObjectName\"].values))\n",
    "        #action_definition_dict_build_v2(df) #Only run this if you want to update the action definition\n",
    "        path_extraction(df)\n",
    "        normalize_user_data(df)\n",
    "        extract_msg(df)\n",
    "        sort_by_time(df)\n",
    "        df.drop(columns = \"Message\")\n",
    "        object_vocab_file_check()\n",
    "        object_type_builder(df,vocab_df[\"Object Type\"])\n",
    "        action_class = action_definition(df)\n",
    "        df[\"Action_Class\"] = action_class\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "        print(\"Building temp file checkpoint...\")\n",
    "        temp_path =os.getcwd()+\"\\\\\"+\"temp\"+\"\\\\\"+\"consolidated_dat.pkl\" \n",
    "        df.to_pickle(temp_path)\n",
    "        print(\"Checkpoint created... If unsuccessful, resume from here.\")\n",
    "        print(\"Deleting old temp file...\")\n",
    "        os.remove(temp_path_1)\n",
    "        print(\"Delete successful\")\n",
    "        print(\"Building final report...\")\n",
    "        df.to_csv('Consolidated_Report.csv')\n",
    "        #os.remove(temp_path)\n",
    "        print(\"Consolidated report built successfully. Thanks!\\nPress any key to exit\")\n",
    "        _ = input(\"\")\n",
    "\n",
    "def sbt_data_collection():\n",
    "    vocab_path = settings_dict['Vocab_Path']\n",
    "    vocab_df = pd.read_excel(vocab_path,header=0,index_col=1).drop(columns=[\"Unnamed: 0\",\"Object\"]).to_dict()\n",
    "    path = settings_dict['File_Path']\n",
    "    df = open_files_in_folder(path)\n",
    "    keep_row = list(np.ones(len(df.loc[:,'ObjectName'].values),dtype=int))\n",
    "    df[\"FilterValue\"] = keep_row\n",
    "    path_extraction(df)\n",
    "    normalize_user_data(df)\n",
    "    extract_msg(df)\n",
    "    sort_by_time(df)\n",
    "    df.drop(columns = \"Message\")\n",
    "    object_type_builder(df,vocab_df[\"Object Type\"], daily_mode = 1)\n",
    "    action_class_path = settings_dict[\"Action_Class_Path\"]\n",
    "    action_class = action_definition(df,action_file_path=action_class_path)\n",
    "    df[\"Action_Class\"] = action_class\n",
    "    df=df.drop(columns=['Unnamed: 0'])\n",
    "    filter_list = parse_filter()\n",
    "    apply_filter(filter_list,df)\n",
    "       \n",
    "\n",
    "#Main program starts here\n",
    "print(\"Reading settings...\")\n",
    "settings_dict = parse_config()\n",
    "if settings_dict['Daily_Mode']!='1':\n",
    "    detailed_mode()\n",
    "else:\n",
    "    sbt_data_collection()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    unique_id = []\n",
    "    for i in range(len(list(df.loc[:,\"ObjectName\"].values))):\n",
    "        unique_id = df.loc[i,\"ObjectName\"]+df.loc[i,\"Sequence\"]+df.loc[i,\"UserID\"]\n",
    "    filt_head = unique_id[0]\n",
    "    for i in range(1,len(unique_id)):\n",
    "        if filt_head==unique_id[i]:\n",
    "            df.drop(index = i, inplace = True)\n",
    "        else:\n",
    "            filt_head = unique_id[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12169\n"
     ]
    }
   ],
   "source": [
    "df2=pd.read_pickle(\"consolidated_dat.pkl\")\n",
    "print(len(list(df2.loc[:,\"ObjectName\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1262616669.0,\n",
       " 1262616677.0,\n",
       " 1262616750.0,\n",
       " 1262616752.0,\n",
       " 1262616765.0,\n",
       " 1262616768.0,\n",
       " 1262616770.0,\n",
       " 1262616781.0,\n",
       " 1262616786.0,\n",
       " 1262616793.0,\n",
       " 1262616797.0,\n",
       " 1262616800.0,\n",
       " 1262616800.0,\n",
       " 1262616802.0,\n",
       " 1262616816.0,\n",
       " 1262616816.0,\n",
       " 1262616817.0,\n",
       " 1262616825.0,\n",
       " 1262616826.0,\n",
       " 1262616869.0,\n",
       " 1262616895.0,\n",
       " 1262617364.0,\n",
       " 1262617369.0,\n",
       " 1262617371.0,\n",
       " 1262617373.0,\n",
       " 1262617375.0,\n",
       " 1262617376.0,\n",
       " 1262617382.0,\n",
       " 1262617385.0,\n",
       " 1262617388.0,\n",
       " 1262617391.0,\n",
       " 1262617441.0,\n",
       " 1262617442.0,\n",
       " 1262617521.0,\n",
       " 1262617642.0,\n",
       " 1262617642.0,\n",
       " 1262617644.0,\n",
       " 1262617710.0,\n",
       " 1262617710.0,\n",
       " 1262617726.0,\n",
       " 1262617729.0,\n",
       " 1262617732.0,\n",
       " 1262617737.0,\n",
       " 1262617882.0,\n",
       " 1262617882.0,\n",
       " 1262617893.0,\n",
       " 1262617897.0,\n",
       " 1262617923.0,\n",
       " 1262617925.0,\n",
       " 1262617927.0,\n",
       " 1262617945.0,\n",
       " 1262617949.0,\n",
       " 1262617949.0,\n",
       " 1262617953.0,\n",
       " 1262617974.0,\n",
       " 1262617990.0,\n",
       " 1262617993.0,\n",
       " 1262617995.0,\n",
       " 1262618042.0,\n",
       " 1262618045.0,\n",
       " 1262618049.0,\n",
       " 1262618055.0,\n",
       " 1262618095.0,\n",
       " 1262618149.0,\n",
       " 1262618836.0,\n",
       " 1262618837.0,\n",
       " 1262618889.0,\n",
       " 1262618914.0,\n",
       " 1262618915.0,\n",
       " 1262618941.0,\n",
       " 1262618977.0,\n",
       " 1262618979.0,\n",
       " 1262618979.0,\n",
       " 1262618979.0,\n",
       " 1262618980.0,\n",
       " 1262619205.0,\n",
       " 1262619341.0,\n",
       " 1262619341.0,\n",
       " 1262619345.0,\n",
       " 1262619355.0,\n",
       " 1262619379.0,\n",
       " 1262619389.0,\n",
       " 1262619391.0,\n",
       " 1262619391.0,\n",
       " 1262619391.0,\n",
       " 1262619391.0,\n",
       " 1262619396.0,\n",
       " 1262619436.0,\n",
       " 1262619436.0,\n",
       " 1262619440.0,\n",
       " 1262619484.0,\n",
       " 1262619657.0,\n",
       " 1262619761.0,\n",
       " 1262619763.0,\n",
       " 1262619764.0,\n",
       " 1262619766.0,\n",
       " 1262619774.0,\n",
       " 1262619782.0,\n",
       " 1262619785.0,\n",
       " 1262619789.0,\n",
       " 1262619791.0,\n",
       " 1262619793.0,\n",
       " 1262619795.0,\n",
       " 1262619797.0,\n",
       " 1262619800.0,\n",
       " 1262619803.0,\n",
       " 1262619807.0,\n",
       " 1262619808.0,\n",
       " 1262619810.0,\n",
       " 1262619811.0,\n",
       " 1262619817.0,\n",
       " 1262619818.0,\n",
       " 1262619841.0,\n",
       " 1262619843.0,\n",
       " 1262619844.0,\n",
       " 1262619861.0,\n",
       " 1262619862.0,\n",
       " 1262619875.0,\n",
       " 1262619877.0,\n",
       " 1262619893.0,\n",
       " 1262619896.0,\n",
       " 1262619897.0,\n",
       " 1262619899.0,\n",
       " 1262619901.0,\n",
       " 1262619904.0,\n",
       " 1262619909.0,\n",
       " 1262619911.0,\n",
       " 1262620191.0,\n",
       " 1262620263.0,\n",
       " 1262620267.0,\n",
       " 1262620296.0,\n",
       " 1262620300.0,\n",
       " 1262620398.0,\n",
       " 1262620401.0,\n",
       " 1262620417.0,\n",
       " 1262620417.0,\n",
       " 1262620420.0,\n",
       " 1262620427.0,\n",
       " 1262620501.0,\n",
       " 1262620502.0,\n",
       " 1262620502.0,\n",
       " 1262620502.0,\n",
       " 1262620504.0,\n",
       " 1262620504.0,\n",
       " 1262620505.0,\n",
       " 1262620505.0,\n",
       " 1262620526.0,\n",
       " 1262620534.0,\n",
       " 1262620534.0,\n",
       " 1262620534.0,\n",
       " 1262620539.0,\n",
       " 1262620539.0,\n",
       " 1262620539.0,\n",
       " 1262620558.0,\n",
       " 1262620558.0,\n",
       " 1262620559.0,\n",
       " 1262620559.0,\n",
       " 1262620559.0,\n",
       " 1262620560.0,\n",
       " 1262620561.0,\n",
       " 1262620612.0,\n",
       " 1262620613.0,\n",
       " 1262620613.0,\n",
       " 1262620613.0,\n",
       " 1262620623.0,\n",
       " 1262620625.0,\n",
       " 1262620625.0,\n",
       " 1262620626.0,\n",
       " 1262620626.0,\n",
       " 1262620627.0,\n",
       " 1262620627.0,\n",
       " 1262620627.0,\n",
       " 1262620628.0,\n",
       " 1262620628.0,\n",
       " 1262620630.0,\n",
       " 1262620632.0,\n",
       " 1262620635.0,\n",
       " 1262620665.0,\n",
       " 1262620668.0,\n",
       " 1262620683.0,\n",
       " 1262620686.0,\n",
       " 1262620686.0,\n",
       " 1262620689.0,\n",
       " 1262620689.0,\n",
       " 1262620689.0,\n",
       " 1262620689.0,\n",
       " 1262620689.0,\n",
       " 1262620692.0,\n",
       " 1262620692.0,\n",
       " 1262620692.0,\n",
       " 1262620695.0,\n",
       " 1262620695.0,\n",
       " 1262620695.0,\n",
       " 1262620695.0,\n",
       " 1262620697.0,\n",
       " 1262620699.0,\n",
       " 1262620699.0,\n",
       " 1262620699.0,\n",
       " 1262620700.0,\n",
       " 1262620700.0,\n",
       " 1262620700.0,\n",
       " 1262620705.0,\n",
       " 1262620711.0,\n",
       " 1262620757.0,\n",
       " 1262620769.0,\n",
       " 1262620774.0,\n",
       " 1262620790.0,\n",
       " 1262620790.0,\n",
       " 1262620792.0,\n",
       " 1262620793.0,\n",
       " 1262620793.0,\n",
       " 1262620796.0,\n",
       " 1262620796.0,\n",
       " 1262620797.0,\n",
       " 1262620797.0,\n",
       " 1262620797.0,\n",
       " 1262620797.0,\n",
       " 1262620797.0,\n",
       " 1262620797.0,\n",
       " 1262620797.0,\n",
       " 1262620799.0,\n",
       " 1262620799.0,\n",
       " 1262620799.0,\n",
       " 1262620801.0,\n",
       " 1262620801.0,\n",
       " 1262620801.0,\n",
       " 1262620802.0,\n",
       " 1262620864.0,\n",
       " 1262620867.0,\n",
       " 1262620868.0,\n",
       " 1262620869.0,\n",
       " 1262620883.0,\n",
       " 1262620897.0,\n",
       " 1262620899.0,\n",
       " 1262620930.0,\n",
       " 1262620932.0,\n",
       " 1262620948.0,\n",
       " 1262620949.0,\n",
       " 1262620949.0,\n",
       " 1262620949.0,\n",
       " 1262620953.0,\n",
       " 1262620989.0,\n",
       " 1262620997.0,\n",
       " 1262621002.0,\n",
       " 1262621033.0,\n",
       " 1262621043.0,\n",
       " 1262621052.0,\n",
       " 1262621052.0,\n",
       " 1262621053.0,\n",
       " 1262621053.0,\n",
       " 1262621053.0,\n",
       " 1262621054.0,\n",
       " 1262621063.0,\n",
       " 1262621113.0,\n",
       " 1262621113.0,\n",
       " 1262621114.0,\n",
       " 1262621117.0,\n",
       " 1262621154.0,\n",
       " 1262621157.0,\n",
       " 1262621170.0,\n",
       " 1262621171.0,\n",
       " 1262621171.0,\n",
       " 1262621171.0,\n",
       " 1262621171.0,\n",
       " 1262621201.0,\n",
       " 1262621201.0,\n",
       " 1262621201.0,\n",
       " 1262621201.0,\n",
       " 1262621202.0,\n",
       " 1262621215.0,\n",
       " 1262621215.0,\n",
       " 1262621216.0,\n",
       " 1262621216.0,\n",
       " 1262621219.0,\n",
       " 1262621219.0,\n",
       " 1262621225.0,\n",
       " 1262621229.0,\n",
       " 1262621237.0,\n",
       " 1262621247.0,\n",
       " 1262621249.0,\n",
       " 1262621251.0,\n",
       " 1262621251.0,\n",
       " 1262621253.0,\n",
       " 1262621257.0,\n",
       " 1262621260.0,\n",
       " 1262621262.0,\n",
       " 1262621264.0,\n",
       " 1262621267.0,\n",
       " 1262621275.0,\n",
       " 1262621281.0,\n",
       " 1262621281.0,\n",
       " 1262621281.0,\n",
       " 1262621284.0,\n",
       " 1262621284.0,\n",
       " 1262621284.0,\n",
       " 1262621315.0,\n",
       " 1262621330.0,\n",
       " 1262621332.0,\n",
       " 1262621333.0,\n",
       " 1262621349.0,\n",
       " 1262621352.0,\n",
       " 1262621353.0,\n",
       " 1262621357.0,\n",
       " 1262621362.0,\n",
       " 1262621364.0,\n",
       " 1262621385.0,\n",
       " 1262621389.0,\n",
       " 1262621402.0,\n",
       " 1262621413.0,\n",
       " 1262621417.0,\n",
       " 1262621417.0,\n",
       " 1262621442.0,\n",
       " 1262621447.0,\n",
       " 1262621449.0,\n",
       " 1262621450.0,\n",
       " 1262621457.0,\n",
       " 1262621477.0,\n",
       " 1262621479.0,\n",
       " 1262621480.0,\n",
       " 1262621493.0,\n",
       " 1262621496.0,\n",
       " 1262621496.0,\n",
       " 1262621497.0,\n",
       " 1262621497.0,\n",
       " 1262621497.0,\n",
       " 1262621497.0,\n",
       " 1262621499.0,\n",
       " 1262621503.0,\n",
       " 1262621505.0,\n",
       " 1262621513.0,\n",
       " 1262621513.0,\n",
       " 1262621513.0,\n",
       " 1262621513.0,\n",
       " 1262621513.0,\n",
       " 1262621514.0,\n",
       " 1262621514.0,\n",
       " 1262621533.0,\n",
       " 1262621539.0,\n",
       " 1262621553.0,\n",
       " 1262621553.0,\n",
       " 1262621555.0,\n",
       " 1262621555.0,\n",
       " 1262621573.0,\n",
       " 1262621605.0,\n",
       " 1262621607.0,\n",
       " 1262621608.0,\n",
       " 1262621609.0,\n",
       " 1262621611.0,\n",
       " 1262621612.0,\n",
       " 1262621613.0,\n",
       " 1262621613.0,\n",
       " 1262621624.0,\n",
       " 1262621626.0,\n",
       " 1262621628.0,\n",
       " 1262621630.0,\n",
       " 1262621632.0,\n",
       " 1262621633.0,\n",
       " 1262621633.0,\n",
       " 1262621635.0,\n",
       " 1262621637.0,\n",
       " 1262621641.0,\n",
       " 1262621642.0,\n",
       " 1262621642.0,\n",
       " 1262621643.0,\n",
       " 1262621644.0,\n",
       " 1262621646.0,\n",
       " 1262621646.0,\n",
       " 1262621646.0,\n",
       " 1262621647.0,\n",
       " 1262621647.0,\n",
       " 1262621653.0,\n",
       " 1262621662.0,\n",
       " 1262621662.0,\n",
       " 1262621663.0,\n",
       " 1262621663.0,\n",
       " 1262621668.0,\n",
       " 1262621668.0,\n",
       " 1262621670.0,\n",
       " 1262621671.0,\n",
       " 1262621672.0,\n",
       " 1262621673.0,\n",
       " 1262621673.0,\n",
       " 1262621673.0,\n",
       " 1262621673.0,\n",
       " 1262621673.0,\n",
       " 1262621695.0,\n",
       " 1262621717.0,\n",
       " 1262621720.0,\n",
       " 1262621720.0,\n",
       " 1262621724.0,\n",
       " 1262621727.0,\n",
       " 1262621727.0,\n",
       " 1262621731.0,\n",
       " 1262621739.0,\n",
       " 1262621742.0,\n",
       " 1262621742.0,\n",
       " 1262621773.0,\n",
       " 1262621777.0,\n",
       " 1262621785.0,\n",
       " 1262621788.0,\n",
       " 1262621789.0,\n",
       " 1262621797.0,\n",
       " 1262621799.0,\n",
       " 1262621801.0,\n",
       " 1262621825.0,\n",
       " 1262621837.0,\n",
       " 1262621839.0,\n",
       " 1262621840.0,\n",
       " 1262621844.0,\n",
       " 1262621845.0,\n",
       " 1262621845.0,\n",
       " 1262621845.0,\n",
       " 1262621845.0,\n",
       " 1262621845.0,\n",
       " 1262621847.0,\n",
       " 1262621848.0,\n",
       " 1262621849.0,\n",
       " 1262621854.0,\n",
       " 1262621857.0,\n",
       " 1262621857.0,\n",
       " 1262621858.0,\n",
       " 1262621858.0,\n",
       " 1262621858.0,\n",
       " 1262621858.0,\n",
       " 1262621860.0,\n",
       " 1262621860.0,\n",
       " 1262621863.0,\n",
       " 1262621873.0,\n",
       " 1262621876.0,\n",
       " 1262621876.0,\n",
       " 1262621884.0,\n",
       " 1262621910.0,\n",
       " 1262621912.0,\n",
       " 1262621913.0,\n",
       " 1262621917.0,\n",
       " 1262621919.0,\n",
       " 1262621920.0,\n",
       " 1262621926.0,\n",
       " 1262621929.0,\n",
       " 1262621929.0,\n",
       " 1262621933.0,\n",
       " 1262621977.0,\n",
       " 1262621977.0,\n",
       " 1262621978.0,\n",
       " 1262621978.0,\n",
       " 1262621978.0,\n",
       " 1262621978.0,\n",
       " 1262621980.0,\n",
       " 1262621980.0,\n",
       " 1262621982.0,\n",
       " 1262621992.0,\n",
       " 1262621999.0,\n",
       " 1262622005.0,\n",
       " 1262622029.0,\n",
       " 1262622033.0,\n",
       " 1262622033.0,\n",
       " 1262622035.0,\n",
       " 1262622036.0,\n",
       " 1262622038.0,\n",
       " 1262622041.0,\n",
       " 1262622050.0,\n",
       " 1262622052.0,\n",
       " 1262622053.0,\n",
       " 1262622074.0,\n",
       " 1262622077.0,\n",
       " 1262622092.0,\n",
       " 1262622092.0,\n",
       " 1262622092.0,\n",
       " 1262622093.0,\n",
       " 1262622093.0,\n",
       " 1262622096.0,\n",
       " 1262622098.0,\n",
       " 1262622106.0,\n",
       " 1262622110.0,\n",
       " 1262622114.0,\n",
       " 1262622115.0,\n",
       " 1262622118.0,\n",
       " 1262622119.0,\n",
       " 1262622137.0,\n",
       " 1262622142.0,\n",
       " 1262622145.0,\n",
       " 1262622151.0,\n",
       " 1262622154.0,\n",
       " 1262622156.0,\n",
       " 1262622160.0,\n",
       " 1262622169.0,\n",
       " 1262622172.0,\n",
       " 1262622173.0,\n",
       " 1262622179.0,\n",
       " 1262622185.0,\n",
       " 1262622188.0,\n",
       " 1262622194.0,\n",
       " 1262622202.0,\n",
       " 1262622202.0,\n",
       " 1262622204.0,\n",
       " 1262622205.0,\n",
       " 1262622210.0,\n",
       " 1262622218.0,\n",
       " 1262622222.0,\n",
       " 1262622223.0,\n",
       " 1262622223.0,\n",
       " 1262622223.0,\n",
       " 1262622223.0,\n",
       " 1262622225.0,\n",
       " 1262622229.0,\n",
       " 1262622233.0,\n",
       " 1262622249.0,\n",
       " 1262622249.0,\n",
       " 1262622252.0,\n",
       " 1262622258.0,\n",
       " 1262622261.0,\n",
       " 1262622262.0,\n",
       " 1262622265.0,\n",
       " 1262622280.0,\n",
       " 1262622290.0,\n",
       " 1262622291.0,\n",
       " 1262622293.0,\n",
       " 1262622293.0,\n",
       " 1262622295.0,\n",
       " 1262622296.0,\n",
       " 1262622297.0,\n",
       " 1262622298.0,\n",
       " 1262622301.0,\n",
       " 1262622305.0,\n",
       " 1262622305.0,\n",
       " 1262622307.0,\n",
       " 1262622309.0,\n",
       " 1262622309.0,\n",
       " 1262622311.0,\n",
       " 1262622312.0,\n",
       " 1262622319.0,\n",
       " 1262622365.0,\n",
       " 1262622365.0,\n",
       " 1262622384.0,\n",
       " 1262622386.0,\n",
       " 1262622390.0,\n",
       " 1262622394.0,\n",
       " 1264776665.0,\n",
       " 1264776668.0,\n",
       " 1264776687.0,\n",
       " 1264776687.0,\n",
       " 1264776687.0,\n",
       " 1264776688.0,\n",
       " 1264776688.0,\n",
       " 1264776688.0,\n",
       " 1264776689.0,\n",
       " 1264776693.0,\n",
       " 1264776695.0,\n",
       " 1264776695.0,\n",
       " 1264776704.0,\n",
       " 1264776714.0,\n",
       " 1264776716.0,\n",
       " 1264776718.0,\n",
       " 1264776719.0,\n",
       " 1264776726.0,\n",
       " 1264776729.0,\n",
       " 1264776732.0,\n",
       " 1264776736.0,\n",
       " 1264776743.0,\n",
       " 1264776743.0,\n",
       " 1264776747.0,\n",
       " 1264776753.0,\n",
       " 1264776755.0,\n",
       " 1264776756.0,\n",
       " 1264776756.0,\n",
       " 1264776756.0,\n",
       " 1264776757.0,\n",
       " 1264776757.0,\n",
       " 1264776765.0,\n",
       " 1264776765.0,\n",
       " 1264776765.0,\n",
       " 1264776773.0,\n",
       " 1264776774.0,\n",
       " 1264776776.0,\n",
       " 1264776776.0,\n",
       " 1264776781.0,\n",
       " 1264776783.0,\n",
       " 1264776785.0,\n",
       " 1264776793.0,\n",
       " 1264776808.0,\n",
       " 1264776814.0,\n",
       " 1264776819.0,\n",
       " 1264776822.0,\n",
       " 1264776835.0,\n",
       " 1264776846.0,\n",
       " 1264776851.0,\n",
       " 1264776853.0,\n",
       " 1264776877.0,\n",
       " 1264776880.0,\n",
       " 1264776881.0,\n",
       " 1264776883.0,\n",
       " 1264776886.0,\n",
       " 1264776891.0,\n",
       " 1264776896.0,\n",
       " 1264776898.0,\n",
       " 1264776900.0,\n",
       " 1264776901.0,\n",
       " 1264776903.0,\n",
       " 1264776903.0,\n",
       " 1264776905.0,\n",
       " 1264776910.0,\n",
       " 1264776911.0,\n",
       " 1264776913.0,\n",
       " 1264776915.0,\n",
       " 1264776915.0,\n",
       " 1264776916.0,\n",
       " 1264776925.0,\n",
       " 1264776927.0,\n",
       " 1264776933.0,\n",
       " 1264776933.0,\n",
       " 1264776935.0,\n",
       " 1264776936.0,\n",
       " 1264776936.0,\n",
       " 1264776937.0,\n",
       " 1264776937.0,\n",
       " 1264776955.0,\n",
       " 1264776959.0,\n",
       " 1264776969.0,\n",
       " 1264776970.0,\n",
       " 1264776974.0,\n",
       " 1264776977.0,\n",
       " 1264776977.0,\n",
       " 1264776979.0,\n",
       " 1264776980.0,\n",
       " 1264776980.0,\n",
       " 1264776981.0,\n",
       " 1264776981.0,\n",
       " 1264776983.0,\n",
       " 1264776984.0,\n",
       " 1264776987.0,\n",
       " 1264776988.0,\n",
       " 1264776989.0,\n",
       " 1264776990.0,\n",
       " 1264776992.0,\n",
       " 1264777037.0,\n",
       " 1264777045.0,\n",
       " 1264777051.0,\n",
       " 1264777053.0,\n",
       " 1264777054.0,\n",
       " 1264777061.0,\n",
       " 1264777125.0,\n",
       " 1264777126.0,\n",
       " 1264777127.0,\n",
       " 1264777129.0,\n",
       " 1264777134.0,\n",
       " 1264777136.0,\n",
       " 1264777136.0,\n",
       " 1264777137.0,\n",
       " 1264777138.0,\n",
       " 1264777138.0,\n",
       " 1264777139.0,\n",
       " 1264777140.0,\n",
       " 1264777141.0,\n",
       " 1264777141.0,\n",
       " 1264777142.0,\n",
       " 1264777142.0,\n",
       " 1264777145.0,\n",
       " 1264777145.0,\n",
       " 1264777147.0,\n",
       " 1264777148.0,\n",
       " 1264777148.0,\n",
       " 1264777150.0,\n",
       " 1264777151.0,\n",
       " 1264777152.0,\n",
       " 1264777153.0,\n",
       " 1264777155.0,\n",
       " 1264777157.0,\n",
       " 1264777157.0,\n",
       " 1264777160.0,\n",
       " 1264777161.0,\n",
       " 1264777163.0,\n",
       " 1264777165.0,\n",
       " 1264777165.0,\n",
       " 1264777167.0,\n",
       " 1264777168.0,\n",
       " 1264777169.0,\n",
       " 1264777169.0,\n",
       " 1264777170.0,\n",
       " 1264777172.0,\n",
       " 1264777173.0,\n",
       " 1264777175.0,\n",
       " 1264777179.0,\n",
       " 1264777183.0,\n",
       " 1264777183.0,\n",
       " 1264777183.0,\n",
       " 1264777184.0,\n",
       " 1264777184.0,\n",
       " 1264777184.0,\n",
       " 1264777186.0,\n",
       " 1264777189.0,\n",
       " 1264777191.0,\n",
       " 1264777193.0,\n",
       " 1264777197.0,\n",
       " 1264777200.0,\n",
       " 1264777201.0,\n",
       " 1264777206.0,\n",
       " 1264777207.0,\n",
       " 1264777208.0,\n",
       " 1264777212.0,\n",
       " 1264777214.0,\n",
       " 1264777222.0,\n",
       " 1264777222.0,\n",
       " 1264777223.0,\n",
       " 1264777223.0,\n",
       " 1264777225.0,\n",
       " 1264777226.0,\n",
       " 1264777229.0,\n",
       " 1264777237.0,\n",
       " 1264777237.0,\n",
       " 1264777241.0,\n",
       " 1264777241.0,\n",
       " 1264777241.0,\n",
       " 1264777241.0,\n",
       " 1264777241.0,\n",
       " 1264777249.0,\n",
       " 1264777249.0,\n",
       " 1264777249.0,\n",
       " 1264777250.0,\n",
       " 1264777251.0,\n",
       " 1264777254.0,\n",
       " 1264777259.0,\n",
       " 1264777259.0,\n",
       " 1264777259.0,\n",
       " 1264777260.0,\n",
       " 1264777261.0,\n",
       " 1264777261.0,\n",
       " 1264777261.0,\n",
       " 1264777263.0,\n",
       " 1264777263.0,\n",
       " 1264777265.0,\n",
       " 1264777265.0,\n",
       " 1264777266.0,\n",
       " 1264777269.0,\n",
       " 1264777270.0,\n",
       " 1264777271.0,\n",
       " 1264777273.0,\n",
       " 1264777275.0,\n",
       " 1264777281.0,\n",
       " 1264777281.0,\n",
       " 1264777283.0,\n",
       " 1264777283.0,\n",
       " 1264777326.0,\n",
       " 1264777328.0,\n",
       " 1264777329.0,\n",
       " 1264777329.0,\n",
       " 1264777331.0,\n",
       " 1264777333.0,\n",
       " 1264777341.0,\n",
       " 1264777342.0,\n",
       " 1264777345.0,\n",
       " 1264777345.0,\n",
       " 1264777350.0,\n",
       " 1264777360.0,\n",
       " 1264777365.0,\n",
       " 1264777368.0,\n",
       " 1264777369.0,\n",
       " 1264777372.0,\n",
       " 1264777373.0,\n",
       " 1264777377.0,\n",
       " 1264777377.0,\n",
       " 1264777377.0,\n",
       " 1264777377.0,\n",
       " 1264777377.0,\n",
       " 1264777378.0,\n",
       " 1264777378.0,\n",
       " 1264777378.0,\n",
       " 1264777378.0,\n",
       " 1264777378.0,\n",
       " 1264777381.0,\n",
       " 1264777381.0,\n",
       " 1264777385.0,\n",
       " 1264777387.0,\n",
       " 1264777388.0,\n",
       " 1264777389.0,\n",
       " 1264777399.0,\n",
       " 1264777402.0,\n",
       " 1264777406.0,\n",
       " 1264777409.0,\n",
       " 1264777414.0,\n",
       " 1264777417.0,\n",
       " 1264777417.0,\n",
       " 1264777418.0,\n",
       " 1264777420.0,\n",
       " 1264777422.0,\n",
       " 1264777422.0,\n",
       " 1264777424.0,\n",
       " 1264777425.0,\n",
       " 1264777425.0,\n",
       " 1264777427.0,\n",
       " 1264777427.0,\n",
       " 1264777429.0,\n",
       " 1264777430.0,\n",
       " 1264777436.0,\n",
       " 1264777437.0,\n",
       " 1264777437.0,\n",
       " 1264777438.0,\n",
       " 1264777440.0,\n",
       " 1264777440.0,\n",
       " 1264777441.0,\n",
       " 1264777443.0,\n",
       " 1264777444.0,\n",
       " 1264777446.0,\n",
       " 1264777447.0,\n",
       " 1264777450.0,\n",
       " 1264777452.0,\n",
       " 1264777454.0,\n",
       " 1264777455.0,\n",
       " 1264777457.0,\n",
       " 1264777458.0,\n",
       " 1264777460.0,\n",
       " 1264777463.0,\n",
       " 1264777463.0,\n",
       " 1264777464.0,\n",
       " 1264777464.0,\n",
       " 1264777464.0,\n",
       " 1264777464.0,\n",
       " 1264777465.0,\n",
       " 1264777465.0,\n",
       " 1264777472.0,\n",
       " 1264777478.0,\n",
       " 1264777484.0,\n",
       " 1264777509.0,\n",
       " 1264777509.0,\n",
       " 1264777520.0,\n",
       " 1264777523.0,\n",
       " 1264777527.0,\n",
       " 1264777527.0,\n",
       " 1264777528.0,\n",
       " 1264777528.0,\n",
       " 1264777529.0,\n",
       " 1264777529.0,\n",
       " 1264777532.0,\n",
       " 1264777532.0,\n",
       " 1264777532.0,\n",
       " 1264777532.0,\n",
       " 1264777540.0,\n",
       " 1264777540.0,\n",
       " 1264777540.0,\n",
       " 1264777542.0,\n",
       " 1264777547.0,\n",
       " 1264777555.0,\n",
       " 1264777555.0,\n",
       " 1264777556.0,\n",
       " 1264777556.0,\n",
       " 1264777557.0,\n",
       " 1264777561.0,\n",
       " 1264777570.0,\n",
       " 1264777570.0,\n",
       " 1264777570.0,\n",
       " 1264777570.0,\n",
       " 1264777570.0,\n",
       " 1264777570.0,\n",
       " 1264777570.0,\n",
       " 1264777570.0,\n",
       " 1264777570.0,\n",
       " 1264777585.0,\n",
       " 1264777589.0,\n",
       " 1264777589.0,\n",
       " 1264777589.0,\n",
       " 1264777589.0,\n",
       " 1264777596.0,\n",
       " 1264777608.0,\n",
       " 1264777608.0,\n",
       " 1264777611.0,\n",
       " 1264777613.0,\n",
       " 1264777615.0,\n",
       " 1264777620.0,\n",
       " 1264777621.0,\n",
       " 1264777621.0,\n",
       " 1264777625.0,\n",
       " 1264777625.0,\n",
       " 1264777625.0,\n",
       " 1264777628.0,\n",
       " 1264777633.0,\n",
       " 1264777633.0,\n",
       " 1264777633.0,\n",
       " 1264777636.0,\n",
       " 1264777636.0,\n",
       " 1264777636.0,\n",
       " 1264777636.0,\n",
       " 1264777649.0,\n",
       " 1264777649.0,\n",
       " 1264777652.0,\n",
       " 1264777654.0,\n",
       " 1264777661.0,\n",
       " 1264777661.0,\n",
       " 1264777661.0,\n",
       " 1264777662.0,\n",
       " 1264777663.0,\n",
       " 1264777663.0,\n",
       " 1264777663.0,\n",
       " 1264777665.0,\n",
       " 1264777665.0,\n",
       " 1264777665.0,\n",
       " 1264777671.0,\n",
       " 1264777672.0,\n",
       " 1264777677.0,\n",
       " 1264777681.0,\n",
       " 1264777681.0,\n",
       " 1264777682.0,\n",
       " 1264777683.0,\n",
       " 1264777684.0,\n",
       " 1264777685.0,\n",
       " 1264777685.0,\n",
       " 1264777689.0,\n",
       " 1264777689.0,\n",
       " 1264777689.0,\n",
       " 1264777689.0,\n",
       " 1264777689.0,\n",
       " 1264777690.0,\n",
       " 1264777700.0,\n",
       " 1264777703.0,\n",
       " 1264777705.0,\n",
       " 1264777709.0,\n",
       " 1264777711.0,\n",
       " 1264777712.0,\n",
       " 1264777717.0,\n",
       " 1264777718.0,\n",
       " 1264777719.0,\n",
       " 1264777723.0,\n",
       " 1264777725.0,\n",
       " 1264777728.0,\n",
       " 1264777729.0,\n",
       " 1264777732.0,\n",
       " 1264777732.0,\n",
       " 1264777732.0,\n",
       " 1264777732.0,\n",
       " 1264777733.0,\n",
       " 1264777737.0,\n",
       " 1264777741.0,\n",
       " 1264777741.0,\n",
       " 1264777741.0,\n",
       " 1264777744.0,\n",
       " 1264777744.0,\n",
       " 1264777744.0,\n",
       " 1264777750.0,\n",
       " 1264777750.0,\n",
       " 1264777750.0,\n",
       " 1264777752.0,\n",
       " 1264777752.0,\n",
       " 1264777752.0,\n",
       " 1264777753.0,\n",
       " 1264777753.0,\n",
       " 1264777753.0,\n",
       " 1264777753.0,\n",
       " 1264777753.0,\n",
       " 1264777756.0,\n",
       " 1264777756.0,\n",
       " 1264777758.0,\n",
       " 1264777761.0,\n",
       " 1264777761.0,\n",
       " 1264777762.0,\n",
       " 1264777762.0,\n",
       " 1264777763.0,\n",
       " 1264777763.0,\n",
       " 1264777765.0,\n",
       " 1264777767.0,\n",
       " 1264777768.0,\n",
       " 1264777769.0,\n",
       " 1264777769.0,\n",
       " 1264777770.0,\n",
       " 1264777775.0,\n",
       " 1264777775.0,\n",
       " 1264777775.0,\n",
       " 1264777776.0,\n",
       " 1264777777.0,\n",
       " 1264777778.0,\n",
       " 1264777781.0,\n",
       " 1264777781.0,\n",
       " 1264777781.0,\n",
       " 1264777782.0,\n",
       " 1264777785.0,\n",
       " 1264777787.0,\n",
       " 1264777796.0,\n",
       " 1264777796.0,\n",
       " 1264777803.0,\n",
       " 1264777808.0,\n",
       " 1264777809.0,\n",
       " 1264777809.0,\n",
       " 1264777809.0,\n",
       " 1264777809.0,\n",
       " 1264777809.0,\n",
       " 1264777809.0,\n",
       " 1264777813.0,\n",
       " 1264777816.0,\n",
       " 1264777821.0,\n",
       " 1264777821.0,\n",
       " 1264777823.0,\n",
       " 1264777825.0,\n",
       " 1264777829.0,\n",
       " 1264777829.0,\n",
       " 1264777829.0,\n",
       " 1264777829.0,\n",
       " 1264777830.0,\n",
       " 1264777831.0,\n",
       " 1264777833.0,\n",
       " 1264777833.0,\n",
       " 1264777837.0,\n",
       " 1264777837.0,\n",
       " 1264777837.0,\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "time = list(df2.loc[:,\"TimeTicks\"].values)\n",
    "for i in range(len(time)):\n",
    "    time[i] = time[i] + (5- time[i]//5)\n",
    "time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(index=i,axis=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_row = list(np.ones(len(list(df.loc[:,'ObjectName'].values)),dtype=int))\n",
    "df[\"FilterValue\"] = keep_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0bbcc249ae5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"df_time.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_pickle(\"df_time.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data(df_test,fil[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_v2(df,filters):\n",
    "    print(\"Applying Filter...\")\n",
    "    file_name = filters[0]\n",
    "    save = filter[2]\n",
    "    for filter in filters[1]:\n",
    "        col_name = filter[0]\n",
    "        val_name = filter[1]\n",
    "        df = df[df[col_name] == val_name]\n",
    "    if save==1:\n",
    "        df.to_csv(file_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filter():\n",
    "    path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"filters.txt\"\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            filt = f.read()\n",
    "    except:\n",
    "        print(\"Error: filters.txt file not found\")\n",
    "        return []\n",
    "    filter_list = []\n",
    "    filt=filt.replace('\\n',\"\").replace(\" \",\"\").replace(\"Filter{\",\"\").replace(\"}\",\"\").replace(\"%\",\" \")\n",
    "    filt=filt.split(\";\")\n",
    "    if len(filt[-1])==0:\n",
    "        filt.pop()\n",
    "    for f in filt:\n",
    "        f = f.split(',')\n",
    "        f[0] = f[0].replace('FileName=','')\n",
    "        f[1] = int(f[1].replace('Save=',''))\n",
    "        f[2] = f[2].replace(\"(\",\"\").replace(\")\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").split('&')\n",
    "        f_list = []\n",
    "        for item in f[2]:\n",
    "            tup = item.split(\"=\")\n",
    "            tup[1] = list(tup[1].split(\"+\"))\n",
    "            tup = tuple(tup)\n",
    "            f_list.append(tup)\n",
    "        f_construct = tuple([f[0],f[1],f_list])\n",
    "        filter_list.append(f_construct)\n",
    "    return filter_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = parse_filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"FilterValue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, filters):\n",
    "    ''' Filter format is like = (FileName = filename.xlsx,Save = 1 or 0,[(Col,[Val1,Val2]),(Col2,[Val1,Val2])])'''\n",
    "    print(\"Applying Filter...\")\n",
    "    filename = filters[0]\n",
    "    save = filters[1]\n",
    "    for filter in filters[2]:\n",
    "        col_name = filter[0]\n",
    "        print(col_name)\n",
    "        values_list = filter[1]\n",
    "        print(values_list)\n",
    "        for i in range(len(list(df.loc[:,'ObjectName'].values))):\n",
    "            row_ = df.loc[i,col_name]\n",
    "            if row_ not in values_list:\n",
    "                df.loc[i,\"FilterValue\"] = 0\n",
    "    df = df[df[\"FilterValue\"] == 1]\n",
    "    if save==1:\n",
    "        save_df(df,filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tuple([2020, 20, 6, 23, 56, 40, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =time.mktime(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}