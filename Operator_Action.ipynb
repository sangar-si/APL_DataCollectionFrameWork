{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600634204666",
   "display_name": "Python 3.7.4 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Welcome to MI Analysis tool\nChoose your mode of operation\n1. Configuration mode...press 1\n2. User mode...press 2\n_________________________________________________\nUser mode selected...Choose execution mode,\n1. Start new analysis\n2. Resume from old analysis\nLoading Temp file...\nTemp file loaded successfully.\nAttempting excel file build operation...\nConsolidated report built successfully. Thanks!\nPress any key to exit...\nVocab File Checked...Found OK!\nLoading files...\nDetected  10  files in the directory\n1 / 10  files read successfully2 / 10  files read successfully3 / 10  files read successfully4 / 10  files read successfully5 / 10  files read successfully6 / 10  files read successfully7 / 10  files read successfully8 / 10  files read successfully9 / 10  files read successfully10 / 10  files read successfully\n\nAll files loaded\nConcatinating files...\nFile concatination sucessful.\nVocab Building started...Reading file...\nRefresing vocab file...\nVocab file is up to date...\nExtracting data from path...\nData Extraction successful\nAdding to Data Frame\nSuccessful\nNormalizing User Data\nAdd user details for  800xaappeng  in the /Utility_Files/Employee_details.xlsx file\nAdd user details for  p00115543  in the /Utility_Files/Employee_details.xlsx file\nAdd user details for  P00112581  in the /Utility_Files/Employee_details.xlsx file\nSuccessful\nExtracting Message Action\nSuccessful\nVocab File Checked...Found OK!\nBuilding temp file checkpoint...\nCheckpoint created... If unsuccessful, resume from here.\nBuilding final report...\nConsolidated report built successfully. Thanks!\nPress any key to exit\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import walk\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "''' Update notes --- Beta V.1.1\n",
    "Added user more and configuration mode. Configuration mode allows us to reset the dictionary files'''\n",
    "\n",
    "\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "\n",
    "#Function that will import all excel files in a folder\n",
    "#It will take in the path as input and return a dataframe will contain a concatination of all entries of all three files\n",
    "\n",
    "def remove_nan(data_f):\n",
    "    #Finding the last row of a file. Extra rows with nan entry is removed here. It also combines all the individual data frames \n",
    "    #into a single data frame\n",
    "    #print('Checking for junk values...')\n",
    "    l = len(data_f)\n",
    "    junk_frames = []\n",
    "    for i in range(l):\n",
    "        if str(data_f.loc[i,'UserAccount']) == 'nan':\n",
    "            junk_frames.append(i)\n",
    "    if len(junk_frames)>0:\n",
    "        # print(len(junk_frames),\" junk values found\")\n",
    "        #print(\"Removing junk frames...\")\n",
    "        data_f.drop(junk_frames,inplace=True)\n",
    "        #print('Successful.')\n",
    "    else:\n",
    "       pass\n",
    "       # print(\"No junk frames found.\")\n",
    "       \n",
    "def open_files_in_folder(path):\n",
    "    #Loading a list of files from a directory\n",
    "    print(\"Loading files...\")\n",
    "\n",
    "    f = []\n",
    "    for (_,_, filenames) in walk(path):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    print('Detected ',len(f),' files in the directory')\n",
    "    dat_frame=[]\n",
    "    for i in range(len(f)):\n",
    "        full_path = path+'\\\\'+f[i]\n",
    "        #print('Reading File ',f[i])\n",
    "        dat_f = pd.read_excel(full_path, index_col = None, header = 2,sheet_name=0, skiprows=0)\n",
    "        remove_nan(dat_f)\n",
    "        dat_frame.append(dat_f)\n",
    "        print(str(i+1),'/',str(len(f)),' files read successfully', end='\\r')\n",
    "    print(\"\\n\")\n",
    "    print(\"All files loaded\")\n",
    "    print(\"Concatinating files...\")\n",
    "    df_concat = pd.concat(dat_frame, ignore_index = True, sort = False)\n",
    "    print(\"File concatination sucessful.\")\n",
    "    \n",
    "    return df_concat\n",
    "#This helps us to open all the excel files in a folder\n",
    "\n",
    "def sort_by_time(df, time_loc = 1):\n",
    "    import time\n",
    "    time_list = []\n",
    "    for i in list(df.iloc[:,1].values):\n",
    "        split_val = i.replace(\"-\",\" \").replace(\":\",\" \").split(\" \")\n",
    "        #t_tuple = ((split_val[2]),(split_val[1]),(split_val[0]),(split_val[3]),(split_val[4]),(split_val[5]),0,0,0)\n",
    "        #print(t_tuple)\n",
    "        t_tuple = (int(split_val[3]),int(split_val[2]),int(split_val[1]),int(split_val[4]),int(split_val[5]),int(split_val[6]),0,0,0)\n",
    "        t_ticks = time.mktime(t_tuple)\n",
    "        time_list.append(t_ticks)\n",
    "    df[\"TimeTicks\"]=time_list\n",
    "    #df.sort_values(\"TimeTicks\",inplace=True,ascending=True)\n",
    "    \n",
    "def path_extraction(df):\n",
    "    block_list = [] #Block name that comes after root\n",
    "    seq_list = [] #individual sequence\n",
    "    change_type = [] #graphics change or logic related\n",
    "    equip_group = [] #Equipment group\n",
    "    end_obj = [] #End object\n",
    "    print(\"Extracting data from path...\")\n",
    "    for i in list(df.loc[:,\"Path\"].values):\n",
    "        loc_split = i.replace(\"]\",\"/\").replace(\"[Location Structure\",\"Graphic Action\").replace(\"[Control Structure\",\"Control Action\").replace(\"SPB_Block\",\"SPB\").replace(\"WBP_Block\",\"WPB\").replace(\"EmulsionBlock\",\"EB\").replace(\"RB_Block\",\"RB\").split(\"/\")\n",
    "        if loc_split[0]==\"Control Action\":\n",
    "            try:\n",
    "                seq_list.append(loc_split[8])\n",
    "            except:\n",
    "                seq_list.append('nan')\n",
    "            \n",
    "            try:\n",
    "                block_list.append(loc_split[3])\n",
    "            except:\n",
    "                block_list.append('nan')\n",
    "                \n",
    "            try:\n",
    "                change_type.append(loc_split[0])\n",
    "            except:\n",
    "                change_type.append(loc_split[0])\n",
    "                \n",
    "            try:    \n",
    "                equip_group.append(loc_split[7])\n",
    "            except:\n",
    "                equip_group.append(loc_split[-2])\n",
    "                \n",
    "            try:   \n",
    "                end_obj.append(loc_split[-1])\n",
    "            except:\n",
    "                end_obj.append(loc_split[-1])\n",
    "        else:\n",
    "            try:\n",
    "                block_list.append(loc_split[2])\n",
    "            except:\n",
    "                block_list.append('nan')\n",
    "                \n",
    "            try:\n",
    "                change_type.append(loc_split[0])\n",
    "            except:\n",
    "                change_type.append('nan')\n",
    "               \n",
    "            try:\n",
    "                end_obj.append(loc_split[-1])\n",
    "            except:\n",
    "                end_obj.append('nan')\n",
    "                \n",
    "            try:\n",
    "                equip_group.append(loc_split[3])\n",
    "            except:\n",
    "                equip_group.append('nan')\n",
    "                \n",
    "            try:\n",
    "                seq_list.append(loc_split[-2])\n",
    "            except:\n",
    "                seq_list.append('nan')  \n",
    "                \n",
    "    print(\"Data Extraction successful\")\n",
    "    print(\"Adding to Data Frame\")\n",
    "    df[\"Block\"] = block_list\n",
    "    df[\"Change Type\"] = change_type\n",
    "    df[\"Equipment Group\"] = equip_group\n",
    "    df[\"Sequence\"] = seq_list\n",
    "    df[\"Object Interacted With\"] = end_obj\n",
    "    print(\"Successful\")\n",
    "    \n",
    "def normalize_user_data(df, file_name = 'Employee_details.xlsx'):\n",
    "    user_id = []\n",
    "    user_name = []\n",
    "    user_dept = []\n",
    "    user_subdept = []\n",
    "    user_designation = []\n",
    "    uknown_id = []\n",
    "    emp_file_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name\n",
    "    emp_details = pd.read_excel(emp_file_path, index_col = 0, header = 0).transpose()\n",
    "    emp_dict = emp_details.to_dict(orient = 'series')\n",
    "    print(\"Normalizing User Data\")\n",
    "    for i in list(df.loc[:,\"UserAccount\"].values):\n",
    "        id_val = i[11:]\n",
    "        try:\n",
    "            emp_details_list = list(emp_dict[id_val].values)\n",
    "        except:\n",
    "            if id_val not in uknown_id:\n",
    "                print(\"Add user details for \",id_val,\" in the /Utility_Files/Employee_details.xlsx file\")\n",
    "                uknown_id.append(id_val)\n",
    "            emp_details_list = ['na','na','na','na']\n",
    "            \n",
    "        user_id.append(id_val)\n",
    "        user_name.append(emp_details_list[0])\n",
    "        user_designation.append(emp_details_list[1])\n",
    "        user_dept.append(emp_details_list[2])\n",
    "        user_subdept.append(emp_details_list[3])\n",
    "        \n",
    "\n",
    "    df[\"UserID\"] = user_id  \n",
    "    df[\"UserName\"] = user_name\n",
    "    df[\"UserDesignation\"] = user_designation\n",
    "    df[\"UserDept\"] = user_dept\n",
    "    df[\"User_Sub_Dept\"] = user_subdept  \n",
    "    print(\"Successful\")\n",
    "    del uknown_id\n",
    "\n",
    "def extract_msg(df):\n",
    "    message = []\n",
    "    print(\"Extracting Message Action\")\n",
    "    for i in list(df.loc[:,\"Message\"].values):\n",
    "        msg = i.split()\n",
    "        message.append(msg[0])\n",
    "    df[\"Action Variable\"] = message\n",
    "    print(\"Successful\")\n",
    "\n",
    "def normalize_object_name(obj_name):\n",
    "    import re\n",
    "    index = re.search(\"[_]|[-]\",obj_name)\n",
    "    if index is None:\n",
    "        index = re.search(\"[0-9]\",obj_name)\n",
    "          \n",
    "        if index is None:\n",
    "            split_index = len(obj_name)\n",
    "        else:\n",
    "            split_index = index.span(0)[0]\n",
    "    else:\n",
    "        split_index = index.span(0)[0]\n",
    "    \n",
    "    return obj_name[0:split_index].lower()\n",
    "\n",
    "def obj_vocab_reader(obj_names, file_name = 'Equip_Vocab.xlsx', refresh = True):\n",
    "    print(\"Vocab Building started...Reading file...\")\n",
    "    import re\n",
    "    if (refresh==False):\n",
    "        obj_vocab_dict_temp={}\n",
    "        obj_equ_list = {\"ID\":[],\"Object\":[],\"Object Type\":[]}\n",
    "    else:\n",
    "        obj_vocab_dict_temp={}\n",
    "        tmp_df = pd.read_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name,header = 0, index_col = 0)\n",
    "        id_list = list(tmp_df[\"ID\"].values)\n",
    "        object_list = list(tmp_df[\"Object\"])\n",
    "        object_type_list = list(tmp_df[\"Object Type\"])\n",
    "        obj_equ_list = {\"ID\":id_list,\"Object\":object_list,\"Object Type\":object_type_list}\n",
    "        for id_val in id_list:\n",
    "            obj_vocab_dict_temp[id_val] = None\n",
    "        print(\"Refresing vocab file...\")\n",
    "    entry_req = False\n",
    "    for obj_name in obj_names:\n",
    "        #We try to split the string at _ first. If _ is not found, then we split at 0-9. If that is not found then we\n",
    "        #retain the entire string\n",
    "        index = re.search(\"[_]|[-]\",obj_name)\n",
    "        if index is None:\n",
    "            index = re.search(\"[0-9]\",obj_name)\n",
    "            \n",
    "            if index is None:\n",
    "                split_index = len(obj_name)\n",
    "            else:\n",
    "                split_index = index.span(0)[0]\n",
    "        else:\n",
    "            split_index = index.span(0)[0]\n",
    "            \n",
    "        if obj_name[0:split_index].lower() in obj_vocab_dict_temp:\n",
    "            pass\n",
    "        else:\n",
    "            obj_vocab_dict_temp[obj_name[0:split_index].lower()]=None\n",
    "            obj_equ_list[\"ID\"].append(obj_name[0:split_index].lower())\n",
    "            obj_equ_list[\"Object\"].append(obj_name)\n",
    "            obj_equ_list[\"Object Type\"].append(None)\n",
    "            entry_req = True\n",
    "            \n",
    "    if entry_req:\n",
    "        print(\"Vocab file needs to be updated...Please make changes in Equip_Vocab.xlsx\")\n",
    "        equip_vocab_df = pd.DataFrame(obj_equ_list)\n",
    "        equip_vocab_df.to_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name)\n",
    "        print(\"Vocab Building completed...File Saved\")\n",
    "    else:\n",
    "        print(\"Vocab file is up to date...\")\n",
    "\n",
    "def object_vocab_file_check(file_name = 'Equip_Vocab.xlsx'):\n",
    "    \n",
    "    vocab_df = pd.read_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name,header=0,index_col=1)\n",
    "    for i in list(vocab_df.loc[:,\"Object Type\"]):\n",
    "        if \"nan\" == str(i):\n",
    "            raise Exception(\"Vocab file has incomplete cells. Complete the vocab file before proceeding forward\")\n",
    "    print(\"Vocab File Checked...Found OK!\")\n",
    "    vocab_df = vocab_df.drop(columns=[\"Unnamed: 0\",\"Object\"]).to_dict()\n",
    "    return  vocab_df[\"Object Type\"]\n",
    "\n",
    "def object_type_builder(df, vocab_df):\n",
    "    object_type = []\n",
    "    for object_name in list(df.loc[:,\"ObjectName\"].values):\n",
    "        norm_obj_name = normalize_object_name(object_name)\n",
    "        object_type.append(vocab_df[norm_obj_name])\n",
    "    df[\"Object Type\"] = object_type\n",
    "    \n",
    "def action_definition_dict_build_v2(df):\n",
    "    \"\"\"\n",
    "    #Accepts data frame as input\n",
    "    #Builds a dictionary of dictionaries. Outputs an excel file which allows us to define actions that are acceptable as MI\n",
    "    \"\"\"\n",
    "    action_var = []\n",
    "    for i in df.loc[:,\"Action Variable\"]:\n",
    "        action_var.append(i)\n",
    "    \n",
    "    action_var_set = set(action_var)\n",
    "    action_var_set = list(action_var_set)\n",
    "    definition_set = [None for c in range(len(action_var_set))]\n",
    "    action_dict={\"Action_Value\":action_var_set,\"Def\":definition_set}    \n",
    "    action_df = pd.DataFrame(action_dict)\n",
    "    action_df.to_excel(\"Action_definition.xlsx\")\n",
    "    \n",
    "def action_definition(df, file_name = \"Action_definition_Final.xlsx\"):\n",
    "    \"\"\"\n",
    "    #This adds action definition to the data frame\n",
    "    \"\"\"\n",
    "    action_file_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name\n",
    "    action_def = pd.read_excel(action_file_path, index_col = 1).drop(columns=[\"Unnamed: 0\"])\n",
    "    action_dict = action_def.to_dict()\n",
    "    action_class = []\n",
    "    for item in df.loc[:,\"Action Variable\"]:\n",
    "        try:\n",
    "            class_type = action_dict[\"Def\"][item]\n",
    "        except KeyError:\n",
    "            class_type = \"NA\"\n",
    "        else:\n",
    "            class_type = \"MI\"\n",
    "        \n",
    "        force_ret = re.findall(\"Force\",item)\n",
    "        if len(force_ret)>0:\n",
    "            class_type = \"MI\"\n",
    "        action_class.append(class_type)\n",
    "    return action_class\n",
    "\n",
    "def config_reset():\n",
    "    path = os.getcwd()     \n",
    "    path = path + \"\\\\\"+ \"Operator_Action_Files\"+\"\\\\\"\n",
    "    df = open_files_in_folder(path)\n",
    "    #oper_data_collective.to_excel('All_oper_action_july.xlsx')\n",
    "\n",
    "    obj_vocab_reader(list(df.loc[:,\"ObjectName\"].values), refresh = False)\n",
    "    action_definition_dict_build_v2(df) #Only run this if you want to update the action definition\n",
    "    exit()\n",
    "\n",
    "def admin_mode_check():\n",
    "    print(\"User Name:\")\n",
    "    u_name = input()\n",
    "    print(\"Password:\")\n",
    "    p_word = input()\n",
    "\n",
    "    if u_name == \"admin\" and p_word ==\"admin\":\n",
    "        config_reset()\n",
    "    else:\n",
    "        print(\"Invalid Credentials... Exiting application... Try again\")\n",
    "        exit()\n",
    "\n",
    "def resume_temp():\n",
    "    temp_path = os.getcwd()+\"\\\\\"+\"temp\"+\"\\\\\"+\"consolidated_dat.pkl\"\n",
    "    print(\"Loading Temp file...\")\n",
    "    try:\n",
    "        df = pd.read_pickle(temp_path)        \n",
    "    except:\n",
    "        print(\"Temp file load error. Check if temp file is available. Else, start new analysis.\")\n",
    "        print(\"Press any key to exit...\")\n",
    "        _ = input(\"\")\n",
    "        exit()\n",
    "    print(\"Temp file loaded successfully.\")\n",
    "\n",
    "    try:\n",
    "        print(\"Attempting excel file build operation...\")\n",
    "        df.to_excel(\"Consolidated_Report.xlsx\")\n",
    "        print(\"Consolidated report built successfully. Thanks!\")\n",
    "\n",
    "    except:\n",
    "        print(\"Excel file build Failed... Attempting csv file build...\")\n",
    "        try:\n",
    "            df.to_csv(\"Consolidated_Report.csv\")\n",
    "            print(\"Consolidated report built successfully. Thanks!\")\n",
    "        except:\n",
    "            print(\"CSV Build also failed... Try running from script\")\n",
    "            exit()\n",
    "    os.remove(temp_path)\n",
    "    print(\"Press any key to exit...\")\n",
    "    _ = input(\"\")\n",
    "    exit()\n",
    "\n",
    "print(\"Welcome to MI Analysis tool\")\n",
    "print(\"Choose your mode of operation\")\n",
    "print(\"1. Configuration mode...press 1\")\n",
    "print(\"2. User mode...press 2\")\n",
    "mode = input(\"\")\n",
    "if mode == '1':\n",
    "    admin_mode_check()\n",
    "print(\"_________________________________________________\")\n",
    "print(\"User mode selected...Choose execution mode,\")\n",
    "print(\"1. Start new analysis\")\n",
    "print(\"2. Resume from old analysis\")\n",
    "mode = input(\"\")\n",
    "if mode == '2':\n",
    "    resume_temp()\n",
    "\n",
    "vocab_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"Equip_Vocab.xlsx\"\n",
    "vocab_df = pd.read_excel(vocab_path,header=0,index_col=1).drop(columns=[\"Unnamed: 0\",\"Object\"]).to_dict()\n",
    "object_vocab_file_check()\n",
    "path = os.getcwd()     \n",
    "path = path + \"\\\\\"+ \"Operator_Action_Files\"+\"\\\\\"\n",
    "df = open_files_in_folder(path)\n",
    "#oper_data_collective.to_excel('All_oper_action_july.xlsx')\n",
    "\n",
    "obj_vocab_reader(list(df.loc[:,\"ObjectName\"].values))\n",
    "#action_definition_dict_build_v2(df) #Only run this if you want to update the action definition\n",
    "\n",
    "path_extraction(df)\n",
    "normalize_user_data(df)\n",
    "extract_msg(df)\n",
    "df.drop(columns = \"Message\")\n",
    "object_vocab_file_check()\n",
    "object_type_builder(df,vocab_df[\"Object Type\"])\n",
    "action_class = action_definition(df)\n",
    "df[\"Action Class\"] = action_class\n",
    "df.drop(columns=['Unnamed: 0'])\n",
    "print(\"Building temp file checkpoint...\")\n",
    "temp_path =os.getcwd()+\"\\\\\"+\"temp\"+\"\\\\\"+\"consolidated_dat.pkl\" \n",
    "df.to_pickle(temp_path)\n",
    "print(\"Checkpoint created... If unsuccessful, resume from here.\")\n",
    "\n",
    "print(\"Building final report...\")\n",
    "df.to_csv('Consolidated_Report.csv')\n",
    "print(\"Consolidated report built successfully. Thanks!\\nPress any key to exit\")\n",
    "_ = input(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}