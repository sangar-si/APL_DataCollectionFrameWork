{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600902788989",
   "display_name": "Python 3.7.4 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Welcome to MI Analysis tool\nChoose your mode of operation\n1. Configuration mode...press 1\n2. User mode...press 2\n_________________________________________________\nUser mode selected...Choose execution mode,\n1. Start new analysis\n2. Resume from old analysis\nLoading Temp file...\nTemp file load error. Check if temp file is available. Else, start new analysis.\nPress any key to exit...\nERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\nTraceback (most recent call last):\n  File \"<ipython-input-2-ad354bd5d9f5>\", line 336, in resume_temp\n    df = pd.read_pickle(temp_path)\n  File \"C:\\Users\\sisat\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\io\\pickle.py\", line 170, in read_pickle\n    f, fh = get_handle(fp_or_buf, \"rb\", compression=compression, is_text=False)\n  File \"C:\\Users\\sisat\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\io\\common.py\", line 434, in get_handle\n    f = open(path_or_buf, mode)\nFileNotFoundError: [Errno 2] No such file or directory: 'd:\\\\Project\\\\GIT\\\\Manual_Intervention\\\\temp\\\\consolidated_dat.pkl'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\sisat\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-ad354bd5d9f5>\", line 375, in <module>\n    resume_temp()\n  File \"<ipython-input-2-ad354bd5d9f5>\", line 341, in resume_temp\n    sys.exit(\"Exiting...\")\nSystemExit: Exiting...\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\sisat\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"C:\\Users\\sisat\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n    return f(*args, **kwargs)\n  File \"C:\\Users\\sisat\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"C:\\Users\\sisat\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\inspect.py\", line 1502, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\nAttributeError: 'tuple' object has no attribute 'tb_frame'\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ad354bd5d9f5>\u001b[0m in \u001b[0;36mresume_temp\u001b[1;34m()\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'd:\\\\Project\\\\GIT\\\\Manual_Intervention\\\\temp\\\\consolidated_dat.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ad354bd5d9f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m     \u001b[0mresume_temp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ad354bd5d9f5>\u001b[0m in \u001b[0;36mresume_temp\u001b[1;34m()\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exiting...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Temp file loaded successfully.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: Exiting...",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2036\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m   2037\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[1;32m-> 2038\u001b[1;33m                                                                      value))\n\u001b[0m\u001b[0;32m   2039\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    821\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m         \"\"\"\n\u001b[1;32m--> 823\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[0;32m    701\u001b[0m                 \u001b[1;33m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m                 + out_list)\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1436\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             )\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1193\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import walk\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "''' Update notes --- Beta V.1.1\n",
    "Added user more and configuration mode. Configuration mode allows us to reset the dictionary files'''\n",
    "\n",
    "\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "\n",
    "#Function that will import all excel files in a folder\n",
    "#It will take in the path as input and return a dataframe will contain a concatination of all entries of all three files\n",
    "\n",
    "def remove_nan(data_f):\n",
    "    #Finding the last row of a file. Extra rows with nan entry is removed here. It also combines all the individual data frames \n",
    "    #into a single data frame\n",
    "    #print('Checking for junk values...')\n",
    "    l = len(data_f)\n",
    "    junk_frames = []\n",
    "    for i in range(l):\n",
    "        if str(data_f.loc[i,'UserAccount']) == 'nan':\n",
    "            junk_frames.append(i)\n",
    "    if len(junk_frames)>0:\n",
    "        # print(len(junk_frames),\" junk values found\")\n",
    "        #print(\"Removing junk frames...\")\n",
    "        data_f.drop(junk_frames,inplace=True)\n",
    "        #print('Successful.')\n",
    "    else:\n",
    "       pass\n",
    "       # print(\"No junk frames found.\")\n",
    "       \n",
    "def open_files_in_folder(path):\n",
    "    #Loading a list of files from a directory\n",
    "    print(\"Loading files...\")\n",
    "\n",
    "    f = []\n",
    "    for (_,_, filenames) in walk(path):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    print('Detected ',len(f),' files in the directory')\n",
    "    dat_frame=[]\n",
    "    for i in range(len(f)):\n",
    "        full_path = path+'\\\\'+f[i]\n",
    "        #print('Reading File ',f[i])\n",
    "        dat_f = pd.read_excel(full_path, index_col = None, header = 2,sheet_name=0, skiprows=0)\n",
    "        remove_nan(dat_f)\n",
    "        dat_frame.append(dat_f)\n",
    "        print(str(i+1),'/',str(len(f)),' files read successfully', end='\\r')\n",
    "    print(\"\\n\")\n",
    "    print(\"All files loaded\")\n",
    "    print(\"Concatinating files...\")\n",
    "    df_concat = pd.concat(dat_frame, ignore_index = True, sort = False)\n",
    "    print(\"File concatination sucessful.\")\n",
    "    \n",
    "    return df_concat\n",
    "#This helps us to open all the excel files in a folder\n",
    "\n",
    "def sort_by_time(df, time_loc = 1):\n",
    "    import time\n",
    "    time_list = []\n",
    "    for i in list(df.iloc[:,1].values):\n",
    "        split_val = i.replace(\"-\",\" \").replace(\":\",\" \").split(\" \")\n",
    "        #t_tuple = ((split_val[2]),(split_val[1]),(split_val[0]),(split_val[3]),(split_val[4]),(split_val[5]),0,0,0)\n",
    "        #print(t_tuple)\n",
    "        t_tuple = (int(split_val[3]),int(split_val[2]),int(split_val[1]),int(split_val[4]),int(split_val[5]),int(split_val[6]),0,0,0)\n",
    "        t_ticks = time.mktime(t_tuple)\n",
    "        time_list.append(t_ticks)\n",
    "    df[\"TimeTicks\"]=time_list\n",
    "    #df.sort_values(\"TimeTicks\",inplace=True,ascending=True)\n",
    "    \n",
    "def path_extraction(df):\n",
    "    block_list = [] #Block name that comes after root\n",
    "    seq_list = [] #individual sequence\n",
    "    change_type = [] #graphics change or logic related\n",
    "    equip_group = [] #Equipment group\n",
    "    end_obj = [] #End object\n",
    "    print(\"Extracting data from path...\")\n",
    "    for i in list(df.loc[:,\"Path\"].values):\n",
    "        loc_split = i.replace(\"]\",\"/\").replace(\"[Location Structure\",\"Graphic Action\").replace(\"[Control Structure\",\"Control Action\").replace(\"SPB_Block\",\"SPB\").replace(\"WBP_Block\",\"WPB\").replace(\"EmulsionBlock\",\"EB\").replace(\"RB_Block\",\"RB\").split(\"/\")\n",
    "        if loc_split[0]==\"Control Action\":\n",
    "            try:\n",
    "                seq_list.append(loc_split[8])\n",
    "            except:\n",
    "                seq_list.append('nan')\n",
    "            \n",
    "            try:\n",
    "                block_list.append(loc_split[3])\n",
    "            except:\n",
    "                block_list.append('nan')\n",
    "                \n",
    "            try:\n",
    "                change_type.append(loc_split[0])\n",
    "            except:\n",
    "                change_type.append(loc_split[0])\n",
    "                \n",
    "            try:    \n",
    "                equip_group.append(loc_split[7])\n",
    "            except:\n",
    "                equip_group.append(loc_split[-2])\n",
    "                \n",
    "            try:   \n",
    "                end_obj.append(loc_split[-1])\n",
    "            except:\n",
    "                end_obj.append(loc_split[-1])\n",
    "        else:\n",
    "            try:\n",
    "                block_list.append(loc_split[2])\n",
    "            except:\n",
    "                block_list.append('nan')\n",
    "                \n",
    "            try:\n",
    "                change_type.append(loc_split[0])\n",
    "            except:\n",
    "                change_type.append('nan')\n",
    "               \n",
    "            try:\n",
    "                end_obj.append(loc_split[-1])\n",
    "            except:\n",
    "                end_obj.append('nan')\n",
    "                \n",
    "            try:\n",
    "                equip_group.append(loc_split[3])\n",
    "            except:\n",
    "                equip_group.append('nan')\n",
    "                \n",
    "            try:\n",
    "                seq_list.append(loc_split[-2])\n",
    "            except:\n",
    "                seq_list.append('nan')  \n",
    "                \n",
    "    print(\"Data Extraction successful\")\n",
    "    print(\"Adding to Data Frame\")\n",
    "    df[\"Block\"] = block_list\n",
    "    df[\"Change Type\"] = change_type\n",
    "    df[\"Equipment Group\"] = equip_group\n",
    "    df[\"Sequence\"] = seq_list\n",
    "    df[\"Object Interacted With\"] = end_obj\n",
    "    print(\"Successful\")\n",
    "    \n",
    "def normalize_user_data(df, file_name = 'Employee_details.xlsx'):\n",
    "    user_id = []\n",
    "    user_name = []\n",
    "    user_dept = []\n",
    "    user_subdept = []\n",
    "    user_designation = []\n",
    "    uknown_id = []\n",
    "    emp_file_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name\n",
    "    emp_details = pd.read_excel(emp_file_path, index_col = 0, header = 0).transpose()\n",
    "    emp_dict = emp_details.to_dict(orient = 'series')\n",
    "    print(\"Normalizing User Data\")\n",
    "    for i in list(df.loc[:,\"UserAccount\"].values):\n",
    "        id_val = i[11:]\n",
    "        try:\n",
    "            emp_details_list = list(emp_dict[id_val].values)\n",
    "        except:\n",
    "            if id_val not in uknown_id:\n",
    "                print(\"Add user details for \",id_val,\" in the /Utility_Files/Employee_details.xlsx file\")\n",
    "                uknown_id.append(id_val)\n",
    "            emp_details_list = ['na','na','na','na']\n",
    "            \n",
    "        user_id.append(id_val)\n",
    "        user_name.append(emp_details_list[0])\n",
    "        user_designation.append(emp_details_list[1])\n",
    "        user_dept.append(emp_details_list[2])\n",
    "        user_subdept.append(emp_details_list[3])\n",
    "        \n",
    "\n",
    "    df[\"UserID\"] = user_id  \n",
    "    df[\"UserName\"] = user_name\n",
    "    df[\"UserDesignation\"] = user_designation\n",
    "    df[\"UserDept\"] = user_dept\n",
    "    df[\"User_Sub_Dept\"] = user_subdept  \n",
    "    print(\"Successful\")\n",
    "    del uknown_id\n",
    "\n",
    "def extract_msg(df):\n",
    "    message = []\n",
    "    print(\"Extracting Message Action\")\n",
    "    for i in list(df.loc[:,\"Message\"].values):\n",
    "        msg = i.split()\n",
    "        message.append(msg[0])\n",
    "    df[\"Action Variable\"] = message\n",
    "    print(\"Successful\")\n",
    "\n",
    "def normalize_object_name(obj_name):\n",
    "    import re\n",
    "    index = re.search(\"[_]|[-]\",obj_name)\n",
    "    if index is None:\n",
    "        index = re.search(\"[0-9]\",obj_name)\n",
    "          \n",
    "        if index is None:\n",
    "            split_index = len(obj_name)\n",
    "        else:\n",
    "            split_index = index.span(0)[0]\n",
    "    else:\n",
    "        split_index = index.span(0)[0]\n",
    "    \n",
    "    return obj_name[0:split_index].lower()\n",
    "\n",
    "def obj_vocab_reader(obj_names, file_name = 'Equip_Vocab.xlsx', refresh = True):\n",
    "    print(\"Vocab Building started...Reading file...\")\n",
    "    import re\n",
    "    if (refresh==False):\n",
    "        obj_vocab_dict_temp={}\n",
    "        obj_equ_list = {\"ID\":[],\"Object\":[],\"Object Type\":[]}\n",
    "    else:\n",
    "        obj_vocab_dict_temp={}\n",
    "        tmp_df = pd.read_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name,header = 0, index_col = 0)\n",
    "        id_list = list(tmp_df[\"ID\"].values)\n",
    "        object_list = list(tmp_df[\"Object\"])\n",
    "        object_type_list = list(tmp_df[\"Object Type\"])\n",
    "        obj_equ_list = {\"ID\":id_list,\"Object\":object_list,\"Object Type\":object_type_list}\n",
    "        for id_val in id_list:\n",
    "            obj_vocab_dict_temp[id_val] = None\n",
    "        print(\"Refresing vocab file...\")\n",
    "    entry_req = False\n",
    "    for obj_name in obj_names:\n",
    "        #We try to split the string at _ first. If _ is not found, then we split at 0-9. If that is not found then we\n",
    "        #retain the entire string\n",
    "        index = re.search(\"[_]|[-]\",obj_name)\n",
    "        if index is None:\n",
    "            index = re.search(\"[0-9]\",obj_name)\n",
    "            \n",
    "            if index is None:\n",
    "                split_index = len(obj_name)\n",
    "            else:\n",
    "                split_index = index.span(0)[0]\n",
    "        else:\n",
    "            split_index = index.span(0)[0]\n",
    "            \n",
    "        if obj_name[0:split_index].lower() in obj_vocab_dict_temp:\n",
    "            pass\n",
    "        else:\n",
    "            obj_vocab_dict_temp[obj_name[0:split_index].lower()]=None\n",
    "            obj_equ_list[\"ID\"].append(obj_name[0:split_index].lower())\n",
    "            obj_equ_list[\"Object\"].append(obj_name)\n",
    "            obj_equ_list[\"Object Type\"].append(None)\n",
    "            entry_req = True\n",
    "            \n",
    "    if entry_req:\n",
    "        print(\"Vocab file needs to be updated...Please make changes in Equip_Vocab.xlsx\")\n",
    "        equip_vocab_df = pd.DataFrame(obj_equ_list)\n",
    "        equip_vocab_df.to_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name)\n",
    "        print(\"Vocab Building completed...File Saved\")\n",
    "    else:\n",
    "        print(\"Vocab file is up to date...\")\n",
    "\n",
    "def object_vocab_file_check(file_name = 'Equip_Vocab.xlsx'):\n",
    "    \n",
    "    vocab_df = pd.read_excel(os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name,header=0,index_col=1)\n",
    "    for i in list(vocab_df.loc[:,\"Object Type\"]):\n",
    "        if \"nan\" == str(i):\n",
    "            raise Exception(\"Vocab file has incomplete cells. Complete the vocab file before proceeding forward\")\n",
    "    print(\"Vocab File Checked...Found OK!\")\n",
    "    vocab_df = vocab_df.drop(columns=[\"Unnamed: 0\",\"Object\"]).to_dict()\n",
    "    return  vocab_df[\"Object Type\"]\n",
    "\n",
    "def object_type_builder(df, vocab_df):\n",
    "    object_type = []\n",
    "    for object_name in list(df.loc[:,\"ObjectName\"].values):\n",
    "        norm_obj_name = normalize_object_name(object_name)\n",
    "        object_type.append(vocab_df[norm_obj_name])\n",
    "    df[\"Object Type\"] = object_type\n",
    "    \n",
    "def action_definition_dict_build_v2(df):\n",
    "    \"\"\"\n",
    "    #Accepts data frame as input\n",
    "    #Builds a dictionary of dictionaries. Outputs an excel file which allows us to define actions that are acceptable as MI\n",
    "    \"\"\"\n",
    "    action_var = []\n",
    "    for i in df.loc[:,\"Action Variable\"]:\n",
    "        action_var.append(i)\n",
    "    \n",
    "    action_var_set = set(action_var)\n",
    "    action_var_set = list(action_var_set)\n",
    "    definition_set = [None for c in range(len(action_var_set))]\n",
    "    action_dict={\"Action_Value\":action_var_set,\"Def\":definition_set}    \n",
    "    action_df = pd.DataFrame(action_dict)\n",
    "    action_df.to_excel(\"Action_definition.xlsx\")\n",
    "    \n",
    "def action_definition(df, file_name = \"Action_definition_Final.xlsx\"):\n",
    "    \"\"\"\n",
    "    #This adds action definition to the data frame\n",
    "    \"\"\"\n",
    "    action_file_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+file_name\n",
    "    action_def = pd.read_excel(action_file_path, index_col = 1).drop(columns=[\"Unnamed: 0\"])\n",
    "    action_dict = action_def.to_dict()\n",
    "    action_class = []\n",
    "    for item in df.loc[:,\"Action Variable\"]:\n",
    "        try:\n",
    "            class_type = action_dict[\"Def\"][item]\n",
    "        except KeyError:\n",
    "            class_type = \"NA\"\n",
    "        else:\n",
    "            class_type = \"MI\"\n",
    "        \n",
    "        force_ret = re.findall(\"Force\",item)\n",
    "        if len(force_ret)>0:\n",
    "            class_type = \"MI\"\n",
    "        action_class.append(class_type)\n",
    "    return action_class\n",
    "\n",
    "def config_reset():\n",
    "    path = os.getcwd()     \n",
    "    path = path + \"\\\\\"+ \"Operator_Action_Files\"+\"\\\\\"\n",
    "    df = open_files_in_folder(path)\n",
    "    #oper_data_collective.to_excel('All_oper_action_july.xlsx')\n",
    "\n",
    "    obj_vocab_reader(list(df.loc[:,\"ObjectName\"].values), refresh = False)\n",
    "    action_definition_dict_build_v2(df) #Only run this if you want to update the action definition\n",
    "    sys.exit(\"Exiting...\")\n",
    "\n",
    "def admin_mode_check():\n",
    "    print(\"User Name:\")\n",
    "    u_name = input()\n",
    "    print(\"Password:\")\n",
    "    p_word = input()\n",
    "\n",
    "    if u_name == \"admin\" and p_word ==\"admin\":\n",
    "        config_reset()\n",
    "    else:\n",
    "        print(\"Invalid Credentials... Exiting application... Try again\")\n",
    "        sys.exit(\"Exiting...\")\n",
    "\n",
    "def resume_temp():\n",
    "    temp_path = os.getcwd()+\"\\\\\"+\"temp\"+\"\\\\\"+\"consolidated_dat.pkl\"\n",
    "    print(\"Loading Temp file...\")\n",
    "    try:\n",
    "        df = pd.read_pickle(temp_path)        \n",
    "    except:\n",
    "        print(\"Temp file load error. Check if temp file is available. Else, start new analysis.\")\n",
    "        print(\"Press any key to exit...\")\n",
    "        _ = input(\"\")\n",
    "        sys.exit(\"Exiting...\")\n",
    "    print(\"Temp file loaded successfully.\")\n",
    "\n",
    "    try:\n",
    "        print(\"Attempting excel file build operation...\")\n",
    "        df.to_excel(\"Consolidated_Report.xlsx\")\n",
    "        print(\"Consolidated report built successfully. Thanks!\")\n",
    "\n",
    "    except:\n",
    "        print(\"Excel file build Failed... Attempting csv file build...\")\n",
    "        try:\n",
    "            df.to_csv(\"Consolidated_Report.csv\")\n",
    "            print(\"Consolidated report built successfully. Thanks!\")\n",
    "        except:\n",
    "            print(\"CSV Build also failed... Try running from script\")\n",
    "            sys.exit(\"Exiting...\")\n",
    "    os.remove(temp_path)\n",
    "    print(\"Press any key to exit...\")\n",
    "    _ = input(\"\")\n",
    "\n",
    "print(\"Welcome to MI Analysis tool\")\n",
    "print(\"Choose your mode of operation\")\n",
    "print(\"1. Configuration mode...press 1\")\n",
    "print(\"2. User mode...press 2\")\n",
    "mode = input(\"\")\n",
    "if mode == '1':\n",
    "    admin_mode_check()\n",
    "print(\"_________________________________________________\")\n",
    "print(\"User mode selected...Choose execution mode,\")\n",
    "print(\"1. Start new analysis\")\n",
    "print(\"2. Resume from old analysis\")\n",
    "mode = input(\"\")\n",
    "if mode == '2':\n",
    "    resume_temp()\n",
    "else:\n",
    "    vocab_path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"Equip_Vocab.xlsx\"\n",
    "    vocab_df = pd.read_excel(vocab_path,header=0,index_col=1).drop(columns=[\"Unnamed: 0\",\"Object\"]).to_dict()\n",
    "    object_vocab_file_check()\n",
    "    path = os.getcwd()     \n",
    "    path = path + \"\\\\\"+ \"Operator_Action_Files\"+\"\\\\\"\n",
    "    df = open_files_in_folder(path)\n",
    "    #oper_data_collective.to_excel('All_oper_action_july.xlsx')\n",
    "\n",
    "    obj_vocab_reader(list(df.loc[:,\"ObjectName\"].values))\n",
    "    #action_definition_dict_build_v2(df) #Only run this if you want to update the action definition\n",
    "\n",
    "    path_extraction(df)\n",
    "    normalize_user_data(df)\n",
    "    extract_msg(df)\n",
    "    df.drop(columns = \"Message\")\n",
    "    object_vocab_file_check()\n",
    "    object_type_builder(df,vocab_df[\"Object Type\"])\n",
    "    action_class = action_definition(df)\n",
    "    df[\"Action Class\"] = action_class\n",
    "    df.drop(columns=['Unnamed: 0'])\n",
    "    print(\"Building temp file checkpoint...\")\n",
    "    temp_path =os.getcwd()+\"\\\\\"+\"temp\"+\"\\\\\"+\"consolidated_dat.pkl\" \n",
    "    df.to_pickle(temp_path)\n",
    "    print(\"Checkpoint created... If unsuccessful, resume from here.\")\n",
    "\n",
    "    print(\"Building final report...\")\n",
    "    df.to_csv('Consolidated_Report.csv')\n",
    "    print(\"Consolidated report built successfully. Thanks!\\nPress any key to exit\")\n",
    "    _ = input(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+\"\\\\\"+\"Utility_Files\"+\"\\\\\"+\"logo.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n            _____ _____          _   _ _____        _____ _   _ _______ _____ \n     /\\    / ____|_   _|   /\\   | \\ | |  __ \\ /\\   |_   _| \\ | |__   __/ ____|\n    /  \\  | (___   | |    /  \\  |  \\| | |__) /  \\    | | |  \\| |  | | | (___  \n   / /\\ \\  \\___ \\  | |   / /\\ \\ | . ` |  ___/ /\\ \\   | | | . ` |  | |  \\___ \\ \n  / ____ \\ ____) |_| |_ / ____ \\| |\\  | |  / ____ \\ _| |_| |\\  |  | |  ____) |\n /_/    \\_\\_____/|_____/_/    \\_\\_| \\_|_| /_/    \\_\\_____|_| \\_|  |_| |_____/ \n                                                                             \n"
    }
   ],
   "source": [
    "with open(path) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}